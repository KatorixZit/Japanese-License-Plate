{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_15032022.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J39MzN8BxmrP",
        "dgubjLneVfSx",
        "YIszf5TdWkOQ",
        "S8fDjqJVbvIU",
        "wiYyN6Mw0Ov2",
        "2hekfW6vpQQy",
        "OuVGAyzhz6Lh",
        "BAhAOMeBqG7U",
        "21Hqda-PeW21",
        "q3tmw8ZZehX1",
        "7EwRLrWbf1LC",
        "yHGRu_OMgFMz",
        "SMRK8phQgZ64",
        "Icy40sk_gxb9",
        "VzlIFv6rtc4L",
        "P_c3hdTQhWGl",
        "4iGNn9-fhWGp",
        "tmqBrjzShWGu",
        "b8odBCN3hWG3",
        "VXf2PTAshmLi",
        "GpDbA5tdhmLs",
        "2uF1ShClhmLu",
        "DI2BfRcxhmLv",
        "OTXqlA2thmLx",
        "HYvLZyWDoVB1",
        "vePIkGPaoVB6"
      ],
      "mount_file_id": "1B33qROTm_0DVFWpGgg-BJY9FPjruF5Dp",
      "authorship_tag": "ABX9TyO2scdS9Yyec6u0q1iu8bLm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valuery/Japanese-License-Plate/blob/main/test_15032022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPETFmbI7rb5",
        "outputId": "ec22cdc7-1e01-445d-9dac-38b344fab90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basepath = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS'"
      ],
      "metadata": {
        "id": "Tr5aa1I48TQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbePy8WuUtBb"
      },
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.append(basepath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $basepath"
      ],
      "metadata": {
        "id": "reHRK6tEUzAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import itertools, os, time\n",
        "import numpy as np\n",
        "from Model import get_Model\n",
        "from parameter import letters\n",
        "import argparse\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_learning_phase(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yRcAmZsU3IO",
        "outputId": "a2b6a38e-507f-4ff6-a8a0-d179619bc8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_label(out):\n",
        "    # out : (1, 32, 42)\n",
        "    out_best = list(np.argmax(out[0, 2:], axis=1))  # get max index -> len = 32\n",
        "    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n",
        "    #print(out_best)\n",
        "    outstr = ''\n",
        "    for i in out_best:\n",
        "        if i < len(letters):\n",
        "            #print(\"->\" + letters[i])\n",
        "            outstr += letters[i]\n",
        "    return outstr"
      ],
      "metadata": {
        "id": "mpVyocwfVA2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
        "    img_pred = img.astype(np.float32)\n",
        "    img_pred = cv2.resize(img_pred, (128, 64))\n",
        "    img_pred = (img_pred / 255.0) * 2.0 - 1.0\n",
        "    img_pred = img_pred.T\n",
        "    img_pred = np.expand_dims(img_pred, axis=-1)\n",
        "    img_pred = np.expand_dims(img_pred, axis=0)\n",
        "    return img_pred"
      ],
      "metadata": {
        "id": "O4tItpJKVXX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_distance(s1, s2):\n",
        "    m=len(s1)+1\n",
        "    n=len(s2)+1\n",
        "\n",
        "    tbl = {}\n",
        "    for i in range(m): tbl[i,0]=i\n",
        "    for j in range(n): tbl[0,j]=j\n",
        "    for i in range(1, m):\n",
        "        for j in range(1, n):\n",
        "            cost = 0 if s1[i-1] == s2[j-1] else 1\n",
        "            tbl[i,j] = min(tbl[i, j-1]+1, tbl[i-1, j]+1, tbl[i-1, j-1]+cost)\n",
        "\n",
        "    return tbl[i,j]"
      ],
      "metadata": {
        "id": "CvO-16YzVZf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77kF15pOkugs",
        "outputId": "607d652f-d12c-4039-f510-5d5d00240c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CHECK TẤT CẢ CÁC CHECKPOINT VỚI TẬP DỮ LIỆU**"
      ],
      "metadata": {
        "id": "J39MzN8BxmrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Check result train_image**"
      ],
      "metadata": {
        "id": "dgubjLneVfSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_2/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "K68XoKZTZA5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjwFpyFjapAo",
        "outputId": "c4b6dd95-aef8-4f5d-8dcc-45f2e57d2a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_dataset_path = os.path.join(basepath, 'dataset/Pipeline_train_and_test/train-real-dataset-area/')\n",
        "image_test_file = os.listdir(train_real_dataset_path)\n",
        "path_test_image = train_real_dataset_path"
      ],
      "metadata": {
        "id": "MYrqZnwSXkrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN = []\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_TRAIN.append(cer_rate)\n",
        "  print(\"CER_TRAIN_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_TRAIN_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_TRAIN_{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CI0GaqN3Vpek",
        "outputId": "0f01b355-ba2f-4a79-fa55-74461b9ff8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_cp-0280.hdf5:  0.015151515151515152\n",
            "ACC_TRAIN_cp-0280.hdf5:  0.9696969696969697\n",
            "letter ACC_TRAIN_cp-0280.hdf5:  0.9857142857142858\n",
            "CER_TRAIN_cp-0240.hdf5:  0.29797979797979796\n",
            "ACC_TRAIN_cp-0240.hdf5:  0.5252525252525253\n",
            "letter ACC_TRAIN_cp-0240.hdf5:  0.6523809523809524\n",
            "CER_TRAIN_cp-0220.hdf5:  0.6683501683501681\n",
            "ACC_TRAIN_cp-0220.hdf5:  0.1111111111111111\n",
            "letter ACC_TRAIN_cp-0220.hdf5:  0.2761904761904762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-16-95b1d91e6397>\", line 16, in <module>\n",
            "    net_out_value = model.predict(img_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1961, in predict\n",
            "    steps_per_execution=self._steps_per_execution)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\", line 1399, in get_data_handler\n",
            "    return DataHandler(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\", line 1161, in __init__\n",
            "    model=model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\", line 326, in __init__\n",
            "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2060, in flat_map\n",
            "    return FlatMapDataset(self, map_func, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5280, in __init__\n",
            "    map_func, self._transformation_name(), dataset=input_dataset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\", line 271, in __init__\n",
            "    self._function = fn_factory()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3071, in get_concrete_function\n",
            "    *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3036, in _get_concrete_function_garbage_collected\n",
            "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3292, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3140, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1202, in func_graph_from_py_func\n",
            "    func_graph.variables = variables\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\", line 522, in __exit__\n",
            "    if (op_is_stateful(op) and not resource_inputs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\", line 150, in op_is_stateful\n",
            "    (op.type in _ALLOWLIST_STATELESS_OPS))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2580, in type\n",
            "    @property\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U23SRP0GaviK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Check result val_image**"
      ],
      "metadata": {
        "id": "YIszf5TdWkOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path ='/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/'\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "6AF44jqWbPlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "a95a7954-b787-4835-c181-5f5c1a56f37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-13bb63092778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "8qtBR_8qbRo2",
        "outputId": "e7539990-d5ed-44f7-eff8-5872ca076fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f70daf74c378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_dataset_path = os.path.join(basepath, 'dataset/Pipeline_train_and_test/val_real_dataset/')\n",
        "image_test_file = os.listdir(test_real_dataset_path)\n",
        "path_test_image = test_real_dataset_path"
      ],
      "metadata": {
        "id": "J9gPYYomX-0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL = []\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_VAL.append(cer_rate)\n",
        "  print(\"CER_VAL_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_VAL_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_VAL{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "id": "5qnRm4jYYJE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lưu kết quả các checkpoint trên toàn bộ tập dữ liệu train và val**"
      ],
      "metadata": {
        "id": "S8fDjqJVbvIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "HEADER = ['CP20', 'CP40', 'CP60', 'CP80', 'CP100', 'CP120', 'CP140', 'CP160', 'CP180', 'CP200']\n",
        "DATA = [\n",
        "        CER_CHECKPOINT_TRAIN,\n",
        "        CER_CHECKPOINT_VAL,\n",
        "]\n",
        "\n",
        "with open('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/result.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    writer.writerow(HEADER)\n",
        "\n",
        "    writer.writerows(DATA)"
      ],
      "metadata": {
        "id": "sqxxyrPObdBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chạy kết quả trên từng class riêng biệt trên tập train, cụ thể là CP120:**"
      ],
      "metadata": {
        "id": "D70Yr2AHeMYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CHECK CP120 CHO TỪNG CLASS RIÊNG BIỆT TRONG TẬP DỮ LIỆU TRAIN VÀ VAL**"
      ],
      "metadata": {
        "id": "wiYyN6Mw0Ov2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/train_real_dataset_classify/'\n",
        "train_real_classify_folder = os.listdir(train_real_classify_path)\n",
        "len(train_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnxUAyCbj6Ki",
        "outputId": "d8d9e0dc-32a7-458a-ef8d-320bd54911b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = []\n",
        "values = []\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  keys.append(folder)\n",
        "  values.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "mR-lHQsSkDbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_train = dict(zip(keys, values))\n",
        "dictionary_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtF189oGmfxH",
        "outputId": "bcdca529-5155-4c3e-9f08-eec3f717a8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 5,\n",
              " '三重': 1,\n",
              " '京': 1,\n",
              " '京都': 14,\n",
              " '八戸': 1,\n",
              " '八王子': 1,\n",
              " '千葉': 3,\n",
              " '名古屋': 2,\n",
              " '和歌山': 1,\n",
              " '和泉': 2,\n",
              " '品川': 5,\n",
              " '多摩': 3,\n",
              " '大宮': 2,\n",
              " '大阪': 7,\n",
              " '奈良': 2,\n",
              " '姫路': 2,\n",
              " '宇都宮': 1,\n",
              " '宮城': 1,\n",
              " '富山': 1,\n",
              " '山梨': 1,\n",
              " '岡山': 1,\n",
              " '川崎': 1,\n",
              " '所沢': 2,\n",
              " '春日部': 1,\n",
              " '横浜': 4,\n",
              " '水戸': 2,\n",
              " '沖': 1,\n",
              " '沼津': 1,\n",
              " '滋賀': 3,\n",
              " '熊谷': 1,\n",
              " '相模': 5,\n",
              " '神戸': 6,\n",
              " '練馬': 1,\n",
              " '群馬': 4,\n",
              " '習志野': 3,\n",
              " '足立': 4,\n",
              " '長野': 1,\n",
              " '静岡': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp6AqpPhqKEF",
        "outputId": "ff369724-73ba-408c-ad60-b096219a615d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ',\n",
              " '三重',\n",
              " '京',\n",
              " '京都',\n",
              " '八戸',\n",
              " '八王子',\n",
              " '千葉',\n",
              " '名古屋',\n",
              " '和歌山',\n",
              " '和泉',\n",
              " '品川',\n",
              " '多摩',\n",
              " '大宮',\n",
              " '大阪',\n",
              " '奈良',\n",
              " '姫路',\n",
              " '宇都宮',\n",
              " '宮城',\n",
              " '富山',\n",
              " '山梨',\n",
              " '岡山',\n",
              " '川崎',\n",
              " '所沢',\n",
              " '春日部',\n",
              " '横浜',\n",
              " '水戸',\n",
              " '沖',\n",
              " '沼津',\n",
              " '滋賀',\n",
              " '熊谷',\n",
              " '相模',\n",
              " '神戸',\n",
              " '練馬',\n",
              " '群馬',\n",
              " '習志野',\n",
              " '足立',\n",
              " '長野',\n",
              " '静岡']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/val_real_dataset_classify/'\n",
        "val_real_classify_folder = os.listdir(val_real_classify_path)\n",
        "len(val_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWa8xFWtpfyR",
        "outputId": "f2dbeb1b-c54f-462e-f9a2-8ecfe44f2dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val = []\n",
        "values_val = []\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  keys_val.append(folder)\n",
        "  values_val.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "mVqJgK-_pqUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys_val, values_val))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD94Xpy1pwgs",
        "outputId": "fdd16da9-1c1e-481a-c806-a37449117911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1,\n",
              " '京都': 2,\n",
              " '八王子': 1,\n",
              " '名古屋': 1,\n",
              " '多摩': 1,\n",
              " '大阪': 1,\n",
              " '春日部': 1,\n",
              " '練馬': 2,\n",
              " '群馬': 1,\n",
              " '足立': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSq_2ASwsxaZ",
        "outputId": "a74556e1-7dcf-4af6-906c-97b5cfdaad06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ', '京都', '八王子', '名古屋', '多摩', '大阪', '春日部', '練馬', '群馬', '足立']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "eWVfOSitoqZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  if folder in keys_val:\n",
        "    print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "    dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbVd91MVm7Tm",
        "outputId": "52a0a3bf-420a-4735-b7ce-0e3a224f0685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69txZJRZttvN",
        "outputId": "4a6dbb16-b783-4236-f9eb-db8964f95375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八王子': 0.3333333333333333,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '多摩': 0.0,\n",
              " '大阪': 0.0,\n",
              " '春日部': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '足立': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST 16032022 - TEST FULL TẬP TRAIN CHO CÁC CLASS Ở CP120\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # if folder in keys_val:\n",
        "  print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTcGb279cmPQ",
        "outputId": "b0f5e0ff-2025-4c69-eb0a-6991c1f569fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_三重:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_千葉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_和歌山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_和泉:  0.25\n",
            "CER_TRAIN_FOR_CLASS_品川:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_奈良:  0.0\n",
            "CER_TRAIN_FOR_CLASS_姫路:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宇都宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宮城:  0.0\n",
            "CER_TRAIN_FOR_CLASS_富山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_山梨:  0.0\n",
            "CER_TRAIN_FOR_CLASS_岡山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_川崎:  0.0\n",
            "CER_TRAIN_FOR_CLASS_所沢:  0.5\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_横浜:  0.0\n",
            "CER_TRAIN_FOR_CLASS_水戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沖:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沼津:  0.0\n",
            "CER_TRAIN_FOR_CLASS_滋賀:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_熊谷:  1.0\n",
            "CER_TRAIN_FOR_CLASS_相模:  0.0\n",
            "CER_TRAIN_FOR_CLASS_神戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_習志野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n",
            "CER_TRAIN_FOR_CLASS_長野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_静岡:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sETvTyJGdX2-",
        "outputId": "9c48e83b-7e52-4580-b966-eb7e40fd389d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '三重': 0.0,\n",
              " '京': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八戸': 0.0,\n",
              " '八王子': 0.3333333333333333,\n",
              " '千葉': 0.0,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '和歌山': 0.0,\n",
              " '和泉': 0.25,\n",
              " '品川': 0.0,\n",
              " '多摩': 0.0,\n",
              " '大宮': 0.0,\n",
              " '大阪': 0.0,\n",
              " '奈良': 0.0,\n",
              " '姫路': 0.0,\n",
              " '宇都宮': 0.0,\n",
              " '宮城': 0.0,\n",
              " '富山': 0.0,\n",
              " '山梨': 0.0,\n",
              " '岡山': 0.0,\n",
              " '川崎': 0.0,\n",
              " '所沢': 0.5,\n",
              " '春日部': 0.0,\n",
              " '横浜': 0.0,\n",
              " '水戸': 0.0,\n",
              " '沖': 0.0,\n",
              " '沼津': 0.0,\n",
              " '滋賀': 0.16666666666666666,\n",
              " '熊谷': 1.0,\n",
              " '相模': 0.0,\n",
              " '神戸': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '習志野': 0.0,\n",
              " '足立': 0.0,\n",
              " '長野': 0.0,\n",
              " '静岡': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chạy kết quả trên từng class riêng biệt trên tập val, cụ thể là CP120**"
      ],
      "metadata": {
        "id": "2hekfW6vpQQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "diHq9PHqpz7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid = {}\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS.append(cer_rate)\n",
        "  dict_val_for_valid[str(folder)] = float(cer_rate)\n",
        "  print(\"CER_VAL_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  # print(\"ACC_VAL_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkBJsAnep0cQ",
        "outputId": "9fc85d35-9cf1-45e4-e67e-a85373b45105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_FOR_CLASS_名古屋:  1.0\n",
            "CER_VAL_FOR_CLASS_なにわ:  1.0\n",
            "CER_VAL_FOR_CLASS_京都:  0.25\n",
            "CER_VAL_FOR_CLASS_八王子:  1.0\n",
            "CER_VAL_FOR_CLASS_大阪:  0.5\n",
            "CER_VAL_FOR_CLASS_多摩:  1.0\n",
            "CER_VAL_FOR_CLASS_群馬:  1.0\n",
            "CER_VAL_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_VAL_FOR_CLASS_練馬:  0.75\n",
            "CER_VAL_FOR_CLASS_足立:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkejsT20u-jI",
        "outputId": "6d7c94ac-1314-41d5-b95f-269cb6e21c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1.0,\n",
              " '京都': 0.25,\n",
              " '八王子': 1.0,\n",
              " '名古屋': 1.0,\n",
              " '多摩': 1.0,\n",
              " '大阪': 0.5,\n",
              " '春日部': 0.3333333333333333,\n",
              " '練馬': 0.75,\n",
              " '群馬': 1.0,\n",
              " '足立': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lưu kết quả**"
      ],
      "metadata": {
        "id": "OuVGAyzhz6Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv \n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/result_specify.csv', 'w', encoding='UTF8', newline='') as output:\n",
        "    cw = csv.writer(output)\n",
        "\n",
        "    for k in dict_val_for_train.keys():\n",
        "      cw.writerow([k, dict_val_for_train[k], dict_val_for_valid[k]])\n",
        "\n",
        "#Chú thích trong file result_specify.csv, cột giá trị '0' biểu trưng cho train, cột giá trị '1' biểu trưng cho valid"
      ],
      "metadata": {
        "id": "O0FxpmrLvN3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST16032022 - Lưu kết quả train cho 38 class ở CP120\n",
        "\n",
        "import csv \n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_specify_for_train_at_class.csv', 'w', encoding='UTF8', newline='') as output:\n",
        "    cw = csv.writer(output)\n",
        "    \n",
        "    for k in dict_val_for_train.keys():\n",
        "      cw.writerow([k, dict_val_for_train[k]])\n",
        "\n",
        "#Chú thích trong file result_specify.csv, cột giá trị '0' biểu trưng cho train, cột giá trị '1' biểu trưng cho valid"
      ],
      "metadata": {
        "id": "xEkfCWy9qfXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Show sample for every class in data**"
      ],
      "metadata": {
        "id": "BAhAOMeBqG7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_output = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/train_output'\n",
        "train_output_file = os.listdir(train_output)\n",
        "len(train_output_file)"
      ],
      "metadata": {
        "id": "ULhRdEmveMkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d97ee0c-b9d6-41d6-e164-ea4666d15626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10094"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for image in train_output_file:\n",
        "    string = ''\n",
        "\n",
        "    for i in range(3):\n",
        "        if image[i]>='0' and image[i]<='9':\n",
        "            continue\n",
        "        else:\n",
        "            string += image[i]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "\n",
        "    labels.append(string)"
      ],
      "metadata": {
        "id": "06hMmfymqda3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sooP_fXtqoHt",
        "outputId": "a6285ee8-cc6f-41ac-fc5d-c1bf50edb2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10094"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "occurences = collections.Counter(labels)\n",
        "occurences "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNcDM2HEqsD1",
        "outputId": "ae97163f-e90f-42c2-ea6b-96b7db4aa59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'なにわ': 516,\n",
              "         '三重': 111,\n",
              "         '京': 116,\n",
              "         '京都': 1383,\n",
              "         '八戸': 106,\n",
              "         '八王子': 120,\n",
              "         '千葉': 317,\n",
              "         '名古屋': 210,\n",
              "         '和歌山': 103,\n",
              "         '和泉': 207,\n",
              "         '品川': 507,\n",
              "         '多摩': 318,\n",
              "         '大宮': 204,\n",
              "         '大阪': 689,\n",
              "         '奈良': 205,\n",
              "         '姫路': 223,\n",
              "         '宇都宮': 102,\n",
              "         '宮城': 91,\n",
              "         '富山': 100,\n",
              "         '山梨': 88,\n",
              "         '岡山': 115,\n",
              "         '川崎': 106,\n",
              "         '所沢': 211,\n",
              "         '春日部': 89,\n",
              "         '横浜': 409,\n",
              "         '水戸': 218,\n",
              "         '沖': 93,\n",
              "         '沼津': 101,\n",
              "         '滋賀': 307,\n",
              "         '熊谷': 98,\n",
              "         '相模': 517,\n",
              "         '神戸': 610,\n",
              "         '練馬': 105,\n",
              "         '群馬': 423,\n",
              "         '習志野': 294,\n",
              "         '足立': 412,\n",
              "         '長野': 85,\n",
              "         '静岡': 185})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_key_train = list(occurences.keys())\n",
        "len(labels_key_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6ra3oQHqxv0",
        "outputId": "bfbfc8ac-384f-4aa0-b5d2-d6a635abccb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vals = [occurences[k] for k in labels_key_train]"
      ],
      "metadata": {
        "id": "8JLNiknNq7uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4l-1km--rAag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.barplot(x=labels_key_train, y=vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IuuVO4clrA2R",
        "outputId": "4826b14f-2773-4187-e68c-b6eba11176b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9c9430a350>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27700 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25144 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22810 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25705 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27798 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27178 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27996 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22823 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38442 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12394 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12395 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12431 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24029 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23822 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20140 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37117 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21517 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21476 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23627 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23019 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 36335 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23713 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23665 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20843 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 19977 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 32722 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24535 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37326 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31070 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 36275 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31435 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 28363 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 36032 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27836 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27941 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 30456 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27169 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21644 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27849 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21697 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25152 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27810 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38745 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22856 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 33391 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 29066 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 35895 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 32676 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 39340 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27468 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 29579 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23376 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21315 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 33865 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23431 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23470 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22478 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23500 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38263 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 32244 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 26792 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 26149 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 26085 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37096 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27700 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 25144 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22810 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 25705 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27798 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27178 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27996 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22823 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38442 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12394 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12395 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12431 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 24029 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23822 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20140 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 37117 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21517 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21476 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23627 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23019 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 36335 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23713 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23665 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20843 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 19977 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 37325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 32722 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 24535 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 37326 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 31070 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 36275 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 31435 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 28363 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 36032 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27836 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27941 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 30456 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27169 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21644 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27849 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21697 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 25152 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27810 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38745 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22856 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 33391 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 29066 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 35895 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 32676 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 39340 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27468 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 29579 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23376 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21315 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 33865 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23431 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23470 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22478 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23500 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38263 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 32244 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 26792 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 26149 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 26085 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 37096 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yZSKHysZrECi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING17032022_FREEZE_LAYERS"
      ],
      "metadata": {
        "id": "21Hqda-PeW21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING_FREEZE25LAYERS_FREEZECNN\n",
        "\n"
      ],
      "metadata": {
        "id": "q3tmw8ZZehX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result train_image**"
      ],
      "metadata": {
        "id": "7EwRLrWbf1LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_3_freeze25layer_freezeCNN/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "mmhvijulf1LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d4ea45c-c2e5-40f4-a2ab-5a737679bcc0",
        "id": "tci0LEGSf1LS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_dataset_path = os.path.join(basepath, 'dataset/Pipeline_train_and_test/train-real-dataset-area/')\n",
        "image_test_file = os.listdir(train_real_dataset_path)\n",
        "path_test_image = train_real_dataset_path"
      ],
      "metadata": {
        "id": "mWm_COYLf1LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_TRAIN[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_TRAIN_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_TRAIN_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_TRAIN_{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f28143-509e-4212-d8b7-f8db66c4dd48",
        "id": "dqtKUwjaf1LT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_cp-0280.hdf5:  0.015151515151515152\n",
            "ACC_TRAIN_cp-0280.hdf5:  0.9696969696969697\n",
            "letter ACC_TRAIN_cp-0280.hdf5:  0.9857142857142858\n",
            "CER_TRAIN_cp-0240.hdf5:  0.29797979797979796\n",
            "ACC_TRAIN_cp-0240.hdf5:  0.5252525252525253\n",
            "letter ACC_TRAIN_cp-0240.hdf5:  0.6523809523809524\n",
            "CER_TRAIN_cp-0220.hdf5:  0.6683501683501681\n",
            "ACC_TRAIN_cp-0220.hdf5:  0.1111111111111111\n",
            "letter ACC_TRAIN_cp-0220.hdf5:  0.2761904761904762\n",
            "CER_TRAIN_cp-0260.hdf5:  0.06481481481481481\n",
            "ACC_TRAIN_cp-0260.hdf5:  0.8585858585858586\n",
            "letter ACC_TRAIN_cp-0260.hdf5:  0.9009433962264151\n",
            "CER_TRAIN_cp-0300.hdf5:  0.005050505050505051\n",
            "ACC_TRAIN_cp-0300.hdf5:  0.98989898989899\n",
            "letter ACC_TRAIN_cp-0300.hdf5:  0.9952380952380953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmxOFbbNf1LT",
        "outputId": "8186f554-d5bd-47e0-c7bc-ff0e3371fb5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.6683501683501681,\n",
              " 'cp-0240': 0.29797979797979796,\n",
              " 'cp-0260': 0.06481481481481481,\n",
              " 'cp-0280': 0.015151515151515152,\n",
              " 'cp-0300': 0.005050505050505051}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result val_image**"
      ],
      "metadata": {
        "id": "yHGRu_OMgFMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_3_freeze25layer_freezeCNN/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "ypdMb4lMgFM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53b0c23-578b-4990-8a84-7c9cf3178cd1",
        "id": "3exe-eH-gFM2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_dataset_path = os.path.join(basepath, 'dataset/Pipeline_train_and_test/val_real_dataset/')\n",
        "image_test_file = os.listdir(test_real_dataset_path)\n",
        "path_test_image = test_real_dataset_path"
      ],
      "metadata": {
        "id": "8iEmOLlzgFM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_VAL[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_VAL_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_VAL_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_VAL{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22ed7b7-ffee-4122-ba58-c917fd0ffb37",
        "id": "PNfXUdUAgFM4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_cp-0280.hdf5:  0.6527777777777778\n",
            "ACC_VAL_cp-0280.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0280.hdf5:  0.20689655172413793\n",
            "CER_VAL_cp-0240.hdf5:  0.75\n",
            "ACC_VAL_cp-0240.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0240.hdf5:  0.17857142857142858\n",
            "CER_VAL_cp-0220.hdf5:  0.8333333333333334\n",
            "ACC_VAL_cp-0220.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0220.hdf5:  0.14285714285714285\n",
            "CER_VAL_cp-0260.hdf5:  0.6666666666666666\n",
            "ACC_VAL_cp-0260.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0260.hdf5:  0.25\n",
            "CER_VAL_cp-0300.hdf5:  0.611111111111111\n",
            "ACC_VAL_cp-0300.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0300.hdf5:  0.2413793103448276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-KX_rVpgP1D",
        "outputId": "446d387e-ea04-4ebc-fd64-78598ff2cbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.8333333333333334,\n",
              " 'cp-0240': 0.75,\n",
              " 'cp-0260': 0.6666666666666666,\n",
              " 'cp-0280': 0.6527777777777778,\n",
              " 'cp-0300': 0.611111111111111}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lưu kết quả các checkpoint trên toàn bộ tập dữ liệu train và val**"
      ],
      "metadata": {
        "id": "WIUQELOwgQSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "HEADER = ['CP20', 'CP40', 'CP60', 'CP80', 'CP100', 'CP120', 'CP140', 'CP160', 'CP180', 'CP200']\n",
        "DATA = [\n",
        "        CER_CHECKPOINT_TRAIN,\n",
        "        CER_CHECKPOINT_VAL,\n",
        "]\n",
        "\n",
        "with open('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/result.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    writer.writerow(HEADER)\n",
        "\n",
        "    writer.writerows(DATA)"
      ],
      "metadata": {
        "id": "ficdsBEDgQSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "d1 = CER_CHECKPOINT_TRAIN\n",
        "d2 = CER_CHECKPOINT_VAL\n",
        "\n",
        "csv_columns = ['cp-0220', 'cp-0240', 'cp-0260', 'cp-0280', 'cp-0300']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_freeze25layers_freezeCNN.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "WFHa66RugZfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECK CP260 CHO TỪNG CLASS RIÊNG BIỆT TRONG TẬP DỮ LIỆU TRAIN**"
      ],
      "metadata": {
        "id": "SMRK8phQgZ64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/train_real_dataset_classify/'\n",
        "train_real_classify_folder = os.listdir(train_real_classify_path)\n",
        "len(train_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eed8346-4445-4874-ede9-02bc491c89ed",
        "id": "fOlWoYfkgZ64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = []\n",
        "values = []\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  keys.append(folder)\n",
        "  values.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "Kl17QgnVgZ64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_train = dict(zip(keys, values))\n",
        "dictionary_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664b41f2-0216-40b8-dc1b-ff635ccd5114",
        "id": "cZC_AgOGgZ64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 5,\n",
              " '三重': 1,\n",
              " '京': 1,\n",
              " '京都': 14,\n",
              " '八戸': 1,\n",
              " '八王子': 1,\n",
              " '千葉': 3,\n",
              " '名古屋': 2,\n",
              " '和歌山': 1,\n",
              " '和泉': 2,\n",
              " '品川': 5,\n",
              " '多摩': 3,\n",
              " '大宮': 2,\n",
              " '大阪': 7,\n",
              " '奈良': 2,\n",
              " '姫路': 2,\n",
              " '宇都宮': 1,\n",
              " '宮城': 1,\n",
              " '富山': 1,\n",
              " '山梨': 1,\n",
              " '岡山': 1,\n",
              " '川崎': 1,\n",
              " '所沢': 2,\n",
              " '春日部': 1,\n",
              " '横浜': 4,\n",
              " '水戸': 2,\n",
              " '沖': 1,\n",
              " '沼津': 1,\n",
              " '滋賀': 3,\n",
              " '熊谷': 1,\n",
              " '相模': 5,\n",
              " '神戸': 6,\n",
              " '練馬': 1,\n",
              " '群馬': 4,\n",
              " '習志野': 3,\n",
              " '足立': 4,\n",
              " '長野': 1,\n",
              " '静岡': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5c39d7-0d9a-4409-8af0-f6ab59671e90",
        "id": "RkKu_bKWgZ64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ',\n",
              " '三重',\n",
              " '京',\n",
              " '京都',\n",
              " '八戸',\n",
              " '八王子',\n",
              " '千葉',\n",
              " '名古屋',\n",
              " '和歌山',\n",
              " '和泉',\n",
              " '品川',\n",
              " '多摩',\n",
              " '大宮',\n",
              " '大阪',\n",
              " '奈良',\n",
              " '姫路',\n",
              " '宇都宮',\n",
              " '宮城',\n",
              " '富山',\n",
              " '山梨',\n",
              " '岡山',\n",
              " '川崎',\n",
              " '所沢',\n",
              " '春日部',\n",
              " '横浜',\n",
              " '水戸',\n",
              " '沖',\n",
              " '沼津',\n",
              " '滋賀',\n",
              " '熊谷',\n",
              " '相模',\n",
              " '神戸',\n",
              " '練馬',\n",
              " '群馬',\n",
              " '習志野',\n",
              " '足立',\n",
              " '長野',\n",
              " '静岡']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/val_real_dataset_classify/'\n",
        "val_real_classify_folder = os.listdir(val_real_classify_path)\n",
        "len(val_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473ca2da-9826-4ea9-d1d4-6dd80aedb7fa",
        "id": "d3EbDUawgZ64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val = []\n",
        "values_val = []\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  keys_val.append(folder)\n",
        "  values_val.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "fHiMTHU-gZ64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_val = dict(zip(keys_val, values_val))\n",
        "dictionary_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6d86f8-ce25-44b1-9f01-cfdbb749d568",
        "id": "AMIhszYXgZ65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1,\n",
              " '京都': 2,\n",
              " '八王子': 1,\n",
              " '名古屋': 1,\n",
              " '多摩': 1,\n",
              " '大阪': 1,\n",
              " '春日部': 1,\n",
              " '練馬': 2,\n",
              " '群馬': 1,\n",
              " '足立': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c2ef32-57f8-47f8-93fb-fa23e351302f",
        "id": "BMiSC-H-gZ65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ', '京都', '八王子', '名古屋', '多摩', '大阪', '春日部', '練馬', '群馬', '足立']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_3_freeze25layer_freezeCNN/cp-0260.hdf5')"
      ],
      "metadata": {
        "id": "TI9JUOesgZ65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check class only in test and log value of train\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  if folder in keys_val:\n",
        "    print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "    dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd43d98-8d8c-46d6-a2a5-ad53c43f9875",
        "id": "bE2z5pL6gZ65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.023809523809523808\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.125\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37b2eca-b8c0-4d99-d594-9e5cb55b7c03",
        "id": "EbpDYyHZgZ65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '京都': 0.023809523809523808,\n",
              " '八王子': 0.0,\n",
              " '名古屋': 0.125,\n",
              " '多摩': 0.16666666666666666,\n",
              " '大阪': 0.0,\n",
              " '春日部': 0.3333333333333333,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.0,\n",
              " '足立': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST 17032022 - TEST FULL TẬP TRAIN CHO CÁC CLASS Ở CP260\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # if folder in keys_val:\n",
        "  print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98784b5-c7be-4f39-80a8-7b4989cfbde8",
        "id": "NfMTfVTIgZ65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_三重:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.023809523809523808\n",
            "CER_TRAIN_FOR_CLASS_八戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.0\n",
            "CER_TRAIN_FOR_CLASS_千葉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.125\n",
            "CER_TRAIN_FOR_CLASS_和歌山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_和泉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_品川:  0.1\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_奈良:  0.0\n",
            "CER_TRAIN_FOR_CLASS_姫路:  0.25\n",
            "CER_TRAIN_FOR_CLASS_宇都宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宮城:  0.5\n",
            "CER_TRAIN_FOR_CLASS_富山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_山梨:  0.5\n",
            "CER_TRAIN_FOR_CLASS_岡山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_川崎:  0.0\n",
            "CER_TRAIN_FOR_CLASS_所沢:  0.25\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_横浜:  0.125\n",
            "CER_TRAIN_FOR_CLASS_水戸:  0.25\n",
            "CER_TRAIN_FOR_CLASS_沖:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沼津:  0.5\n",
            "CER_TRAIN_FOR_CLASS_滋賀:  0.0\n",
            "CER_TRAIN_FOR_CLASS_熊谷:  0.5\n",
            "CER_TRAIN_FOR_CLASS_相模:  0.0\n",
            "CER_TRAIN_FOR_CLASS_神戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_習志野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n",
            "CER_TRAIN_FOR_CLASS_長野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_静岡:  0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8191b25-7b5f-4ab7-bd1a-383df1176f7c",
        "id": "6giGl_lvgZ65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '三重': 0.0,\n",
              " '京': 0.0,\n",
              " '京都': 0.023809523809523808,\n",
              " '八戸': 0.0,\n",
              " '八王子': 0.0,\n",
              " '千葉': 0.0,\n",
              " '名古屋': 0.125,\n",
              " '和歌山': 0.0,\n",
              " '和泉': 0.0,\n",
              " '品川': 0.1,\n",
              " '多摩': 0.16666666666666666,\n",
              " '大宮': 0.0,\n",
              " '大阪': 0.0,\n",
              " '奈良': 0.0,\n",
              " '姫路': 0.25,\n",
              " '宇都宮': 0.0,\n",
              " '宮城': 0.5,\n",
              " '富山': 0.0,\n",
              " '山梨': 0.5,\n",
              " '岡山': 0.0,\n",
              " '川崎': 0.0,\n",
              " '所沢': 0.25,\n",
              " '春日部': 0.3333333333333333,\n",
              " '横浜': 0.125,\n",
              " '水戸': 0.25,\n",
              " '沖': 0.0,\n",
              " '沼津': 0.5,\n",
              " '滋賀': 0.0,\n",
              " '熊谷': 0.5,\n",
              " '相模': 0.0,\n",
              " '神戸': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.0,\n",
              " '習志野': 0.0,\n",
              " '足立': 0.0,\n",
              " '長野': 0.0,\n",
              " '静岡': 0.25}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1T2ut2lvgxI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chạy kết quả trên từng class riêng biệt trên tập val, cụ thể là CP260**"
      ],
      "metadata": {
        "id": "Icy40sk_gxb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_3_freeze25layer_freezeCNN/cp-0260.hdf5')"
      ],
      "metadata": {
        "id": "Mx2p3r9Pgxb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid = {}\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS.append(cer_rate)\n",
        "  dict_val_for_valid[str(folder)] = float(cer_rate)\n",
        "  print(\"CER_VAL_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  # print(\"ACC_VAL_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22cb96d8-21f5-4864-8458-a85e7c8bfc1b",
        "id": "5ACyDBv5gxb_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_FOR_CLASS_なにわ:  1.0\n",
            "CER_VAL_FOR_CLASS_京都:  0.0\n",
            "CER_VAL_FOR_CLASS_八王子:  1.0\n",
            "CER_VAL_FOR_CLASS_名古屋:  1.0\n",
            "CER_VAL_FOR_CLASS_多摩:  0.5\n",
            "CER_VAL_FOR_CLASS_大阪:  0.5\n",
            "CER_VAL_FOR_CLASS_春日部:  1.0\n",
            "CER_VAL_FOR_CLASS_練馬:  0.75\n",
            "CER_VAL_FOR_CLASS_群馬:  1.0\n",
            "CER_VAL_FOR_CLASS_足立:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97962870-ca2a-4af4-ebf3-d1063411e206",
        "id": "tf_g0V_GgxcA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1.0,\n",
              " '京都': 0.0,\n",
              " '八王子': 1.0,\n",
              " '名古屋': 1.0,\n",
              " '多摩': 0.5,\n",
              " '大阪': 0.5,\n",
              " '春日部': 1.0,\n",
              " '練馬': 0.75,\n",
              " '群馬': 1.0,\n",
              " '足立': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lưu kết quả** "
      ],
      "metadata": {
        "id": "VzlIFv6rtc4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "d1 = dict_val_for_train\n",
        "d2 = dict_val_for_valid\n",
        "\n",
        "csv_columns = ['なにわ',\n",
        " '三重',\n",
        " '京',\n",
        " '京都',\n",
        " '八戸',\n",
        " '八王子',\n",
        " '千葉',\n",
        " '名古屋',\n",
        " '和歌山',\n",
        " '和泉',\n",
        " '品川',\n",
        " '多摩',\n",
        " '大宮',\n",
        " '大阪',\n",
        " '奈良',\n",
        " '姫路',\n",
        " '宇都宮',\n",
        " '宮城',\n",
        " '富山',\n",
        " '山梨',\n",
        " '岡山',\n",
        " '川崎',\n",
        " '所沢',\n",
        " '春日部',\n",
        " '横浜',\n",
        " '水戸',\n",
        " '沖',\n",
        " '沼津',\n",
        " '滋賀',\n",
        " '熊谷',\n",
        " '相模',\n",
        " '神戸',\n",
        " '練馬',\n",
        " '群馬',\n",
        " '習志野',\n",
        " '足立',\n",
        " '長野',\n",
        " '静岡']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_freeze25layers_freezeCNN_specify_for_class.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "aDWVePkgg0SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "d1 = dictionary_train \n",
        "d2 = dictionary_val\n",
        "csv_columns = ['なにわ',\n",
        " '三重',\n",
        " '京',\n",
        " '京都',\n",
        " '八戸',\n",
        " '八王子',\n",
        " '千葉',\n",
        " '名古屋',\n",
        " '和歌山',\n",
        " '和泉',\n",
        " '品川',\n",
        " '多摩',\n",
        " '大宮',\n",
        " '大阪',\n",
        " '奈良',\n",
        " '姫路',\n",
        " '宇都宮',\n",
        " '宮城',\n",
        " '富山',\n",
        " '山梨',\n",
        " '岡山',\n",
        " '川崎',\n",
        " '所沢',\n",
        " '春日部',\n",
        " '横浜',\n",
        " '水戸',\n",
        " '沖',\n",
        " '沼津',\n",
        " '滋賀',\n",
        " '熊谷',\n",
        " '相模',\n",
        " '神戸',\n",
        " '練馬',\n",
        " '群馬',\n",
        " '習志野',\n",
        " '足立',\n",
        " '長野',\n",
        " '静岡']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/samples_in_every_class.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "6gUn39JphVu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING_FREEZE31LAYERS_FREEZE_ONEPART_OF_RNN\n",
        "\n"
      ],
      "metadata": {
        "id": "P_c3hdTQhWGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result train_image**"
      ],
      "metadata": {
        "id": "8LOCQ0HDhWGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_4_freeze31layer_one_part_of_RNN/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "5wCXTZs2hWGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99dd710d-3d18-49cf-a243-600538d2a4ac",
        "id": "a14LxzeKhWGm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_dataset_path = os.path.join(basepath, 'dataset/Pipeline_train_and_test/train-real-dataset-area/')\n",
        "image_test_file = os.listdir(train_real_dataset_path)\n",
        "path_test_image = train_real_dataset_path"
      ],
      "metadata": {
        "id": "9rE5xHzshWGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_TRAIN[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_TRAIN_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_TRAIN_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_TRAIN_{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5844f1-5f31-4531-9da1-2da121aa5a81",
        "id": "hFxOAjQJhWGo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_cp-0220.hdf5:  0.5286195286195287\n",
            "ACC_TRAIN_cp-0220.hdf5:  0.2222222222222222\n",
            "letter ACC_TRAIN_cp-0220.hdf5:  0.3744075829383886\n",
            "CER_TRAIN_cp-0280.hdf5:  0.010101010101010102\n",
            "ACC_TRAIN_cp-0280.hdf5:  0.98989898989899\n",
            "letter ACC_TRAIN_cp-0280.hdf5:  0.9904761904761905\n",
            "CER_TRAIN_cp-0240.hdf5:  0.10101010101010101\n",
            "ACC_TRAIN_cp-0240.hdf5:  0.797979797979798\n",
            "letter ACC_TRAIN_cp-0240.hdf5:  0.8428571428571429\n",
            "CER_TRAIN_cp-0300.hdf5:  0.003367003367003367\n",
            "ACC_TRAIN_cp-0300.hdf5:  0.98989898989899\n",
            "letter ACC_TRAIN_cp-0300.hdf5:  0.995260663507109\n",
            "CER_TRAIN_cp-0260.hdf5:  0.018518518518518517\n",
            "ACC_TRAIN_cp-0260.hdf5:  0.9595959595959596\n",
            "letter ACC_TRAIN_cp-0260.hdf5:  0.9715639810426541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3yc1-1BhWGp",
        "outputId": "12265f7e-30ee-442c-9a56-2e277ab0449d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.5286195286195287,\n",
              " 'cp-0240': 0.10101010101010101,\n",
              " 'cp-0260': 0.018518518518518517,\n",
              " 'cp-0280': 0.010101010101010102,\n",
              " 'cp-0300': 0.003367003367003367}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result val_image**"
      ],
      "metadata": {
        "id": "4iGNn9-fhWGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_4_freeze31layer_one_part_of_RNN/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "8VTSbb-RhWGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3333f45c-f089-45c4-c612-2048e72b1a4d",
        "id": "iV7_x02fhWGq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_dataset_path = os.path.join(basepath, 'dataset/Pipeline_train_and_test/val_real_dataset/')\n",
        "image_test_file = os.listdir(test_real_dataset_path)\n",
        "path_test_image = test_real_dataset_path"
      ],
      "metadata": {
        "id": "ioLc_qqehWGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_VAL[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_VAL_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_VAL_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_VAL{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5364b8a9-16fe-4e28-a00e-832fbbb06c81",
        "id": "foPtvhp-hWGr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_cp-0220.hdf5:  0.7916666666666666\n",
            "ACC_VAL_cp-0220.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0220.hdf5:  0.14285714285714285\n",
            "CER_VAL_cp-0280.hdf5:  0.6111111111111112\n",
            "ACC_VAL_cp-0280.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0280.hdf5:  0.32142857142857145\n",
            "CER_VAL_cp-0240.hdf5:  0.7083333333333334\n",
            "ACC_VAL_cp-0240.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0240.hdf5:  0.21428571428571427\n",
            "CER_VAL_cp-0300.hdf5:  0.5694444444444444\n",
            "ACC_VAL_cp-0300.hdf5:  0.25\n",
            "letter ACC_VALcp-0300.hdf5:  0.35714285714285715\n",
            "CER_VAL_cp-0260.hdf5:  0.6111111111111112\n",
            "ACC_VAL_cp-0260.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0260.hdf5:  0.2857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H4a2xOAhWGs",
        "outputId": "0ca4d6f9-092e-4b0d-a0d6-8db5bbd3f6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.7916666666666666,\n",
              " 'cp-0240': 0.7083333333333334,\n",
              " 'cp-0260': 0.6111111111111112,\n",
              " 'cp-0280': 0.6111111111111112,\n",
              " 'cp-0300': 0.5694444444444444}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lưu kết quả các checkpoint trên toàn bộ tập dữ liệu train và val**"
      ],
      "metadata": {
        "id": "ND_sJXfYhWGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "d1 = CER_CHECKPOINT_TRAIN\n",
        "d2 = CER_CHECKPOINT_VAL\n",
        "\n",
        "csv_columns = ['cp-0220', 'cp-0240', 'cp-0260', 'cp-0280', 'cp-0300']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_freeze31layers_freeze_one_part_of_RNN.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "1mIkNA4XhWGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECK CP100 CHO TỪNG CLASS RIÊNG BIỆT TRONG TẬP DỮ LIỆU TRAIN VÀ VAL**"
      ],
      "metadata": {
        "id": "tmqBrjzShWGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/train_real_dataset_classify/'\n",
        "train_real_classify_folder = os.listdir(train_real_classify_path)\n",
        "len(train_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b45db1-312c-413c-a3d7-9f2655c714ab",
        "id": "Q8WPfs8mhWGu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = []\n",
        "values = []\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  keys.append(folder)\n",
        "  values.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "olt0FVzchWGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys, values))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f40d93-e1b1-4992-df6f-d48960c96f1f",
        "id": "VnSycTQghWGv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 5,\n",
              " '三重': 1,\n",
              " '京': 1,\n",
              " '京都': 14,\n",
              " '八戸': 1,\n",
              " '八王子': 1,\n",
              " '千葉': 3,\n",
              " '名古屋': 2,\n",
              " '和歌山': 1,\n",
              " '和泉': 2,\n",
              " '品川': 5,\n",
              " '多摩': 3,\n",
              " '大宮': 2,\n",
              " '大阪': 7,\n",
              " '奈良': 2,\n",
              " '姫路': 2,\n",
              " '宇都宮': 1,\n",
              " '宮城': 1,\n",
              " '富山': 1,\n",
              " '山梨': 1,\n",
              " '岡山': 1,\n",
              " '川崎': 1,\n",
              " '所沢': 2,\n",
              " '春日部': 1,\n",
              " '横浜': 4,\n",
              " '水戸': 2,\n",
              " '沖': 1,\n",
              " '沼津': 1,\n",
              " '滋賀': 3,\n",
              " '熊谷': 1,\n",
              " '相模': 5,\n",
              " '神戸': 6,\n",
              " '練馬': 1,\n",
              " '群馬': 4,\n",
              " '習志野': 3,\n",
              " '足立': 4,\n",
              " '長野': 1,\n",
              " '静岡': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff369724-73ba-408c-ad60-b096219a615d",
        "id": "GHlq80L5hWGw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ',\n",
              " '三重',\n",
              " '京',\n",
              " '京都',\n",
              " '八戸',\n",
              " '八王子',\n",
              " '千葉',\n",
              " '名古屋',\n",
              " '和歌山',\n",
              " '和泉',\n",
              " '品川',\n",
              " '多摩',\n",
              " '大宮',\n",
              " '大阪',\n",
              " '奈良',\n",
              " '姫路',\n",
              " '宇都宮',\n",
              " '宮城',\n",
              " '富山',\n",
              " '山梨',\n",
              " '岡山',\n",
              " '川崎',\n",
              " '所沢',\n",
              " '春日部',\n",
              " '横浜',\n",
              " '水戸',\n",
              " '沖',\n",
              " '沼津',\n",
              " '滋賀',\n",
              " '熊谷',\n",
              " '相模',\n",
              " '神戸',\n",
              " '練馬',\n",
              " '群馬',\n",
              " '習志野',\n",
              " '足立',\n",
              " '長野',\n",
              " '静岡']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/val_real_dataset_classify/'\n",
        "val_real_classify_folder = os.listdir(val_real_classify_path)\n",
        "len(val_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dbeb1b-c54f-462e-f9a2-8ecfe44f2dc9",
        "id": "05z9aX_UhWGw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val = []\n",
        "values_val = []\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  keys_val.append(folder)\n",
        "  values_val.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "epDFdVcxhWGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys_val, values_val))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd16da9-1c1e-481a-c806-a37449117911",
        "id": "qE14LFuthWGx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1,\n",
              " '京都': 2,\n",
              " '八王子': 1,\n",
              " '名古屋': 1,\n",
              " '多摩': 1,\n",
              " '大阪': 1,\n",
              " '春日部': 1,\n",
              " '練馬': 2,\n",
              " '群馬': 1,\n",
              " '足立': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74556e1-7dcf-4af6-906c-97b5cfdaad06",
        "id": "37hIvrsKhWGy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ', '京都', '八王子', '名古屋', '多摩', '大阪', '春日部', '練馬', '群馬', '足立']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "m-ak1PMVhWGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  if folder in keys_val:\n",
        "    print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "    dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a0a3bf-420a-4735-b7ce-0e3a224f0685",
        "id": "HjRSd8lihWGz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6dbb16-b783-4236-f9eb-db8964f95375",
        "id": "TSvtbVY6hWG1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八王子': 0.3333333333333333,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '多摩': 0.0,\n",
              " '大阪': 0.0,\n",
              " '春日部': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '足立': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST 16032022 - TEST FULL TẬP TRAIN CHO CÁC CLASS Ở CP120\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # if folder in keys_val:\n",
        "  print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5e0ff-2025-4c69-eb0a-6991c1f569fe",
        "id": "U-NMVd7DhWG1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_三重:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_千葉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_和歌山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_和泉:  0.25\n",
            "CER_TRAIN_FOR_CLASS_品川:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_奈良:  0.0\n",
            "CER_TRAIN_FOR_CLASS_姫路:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宇都宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宮城:  0.0\n",
            "CER_TRAIN_FOR_CLASS_富山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_山梨:  0.0\n",
            "CER_TRAIN_FOR_CLASS_岡山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_川崎:  0.0\n",
            "CER_TRAIN_FOR_CLASS_所沢:  0.5\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_横浜:  0.0\n",
            "CER_TRAIN_FOR_CLASS_水戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沖:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沼津:  0.0\n",
            "CER_TRAIN_FOR_CLASS_滋賀:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_熊谷:  1.0\n",
            "CER_TRAIN_FOR_CLASS_相模:  0.0\n",
            "CER_TRAIN_FOR_CLASS_神戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_習志野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n",
            "CER_TRAIN_FOR_CLASS_長野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_静岡:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c48e83b-7e52-4580-b966-eb7e40fd389d",
        "id": "gUx_uLE9hWG2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '三重': 0.0,\n",
              " '京': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八戸': 0.0,\n",
              " '八王子': 0.3333333333333333,\n",
              " '千葉': 0.0,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '和歌山': 0.0,\n",
              " '和泉': 0.25,\n",
              " '品川': 0.0,\n",
              " '多摩': 0.0,\n",
              " '大宮': 0.0,\n",
              " '大阪': 0.0,\n",
              " '奈良': 0.0,\n",
              " '姫路': 0.0,\n",
              " '宇都宮': 0.0,\n",
              " '宮城': 0.0,\n",
              " '富山': 0.0,\n",
              " '山梨': 0.0,\n",
              " '岡山': 0.0,\n",
              " '川崎': 0.0,\n",
              " '所沢': 0.5,\n",
              " '春日部': 0.0,\n",
              " '横浜': 0.0,\n",
              " '水戸': 0.0,\n",
              " '沖': 0.0,\n",
              " '沼津': 0.0,\n",
              " '滋賀': 0.16666666666666666,\n",
              " '熊谷': 1.0,\n",
              " '相模': 0.0,\n",
              " '神戸': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '習志野': 0.0,\n",
              " '足立': 0.0,\n",
              " '長野': 0.0,\n",
              " '静岡': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "44G50jH3hWG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chạy kết quả trên từng class riêng biệt trên tập val, cụ thể là CP100**"
      ],
      "metadata": {
        "id": "b8odBCN3hWG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "0rtmvREzhWG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid = {}\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS.append(cer_rate)\n",
        "  dict_val_for_valid[str(folder)] = float(cer_rate)\n",
        "  print(\"CER_VAL_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  # print(\"ACC_VAL_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc85d35-9cf1-45e4-e67e-a85373b45105",
        "id": "Pto026m5hWG4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_FOR_CLASS_名古屋:  1.0\n",
            "CER_VAL_FOR_CLASS_なにわ:  1.0\n",
            "CER_VAL_FOR_CLASS_京都:  0.25\n",
            "CER_VAL_FOR_CLASS_八王子:  1.0\n",
            "CER_VAL_FOR_CLASS_大阪:  0.5\n",
            "CER_VAL_FOR_CLASS_多摩:  1.0\n",
            "CER_VAL_FOR_CLASS_群馬:  1.0\n",
            "CER_VAL_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_VAL_FOR_CLASS_練馬:  0.75\n",
            "CER_VAL_FOR_CLASS_足立:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7c94ac-1314-41d5-b95f-269cb6e21c6a",
        "id": "7wps3EXRhWG4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1.0,\n",
              " '京都': 0.25,\n",
              " '八王子': 1.0,\n",
              " '名古屋': 1.0,\n",
              " '多摩': 1.0,\n",
              " '大阪': 0.5,\n",
              " '春日部': 0.3333333333333333,\n",
              " '練馬': 0.75,\n",
              " '群馬': 1.0,\n",
              " '足立': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Z10ai_3hWG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING_FREEZE35LAYERS_FREEZECRNN\n",
        "\n"
      ],
      "metadata": {
        "id": "VXf2PTAshmLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result train_image**"
      ],
      "metadata": {
        "id": "GpDbA5tdhmLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_5_freeze35layer_fullfreezeuntildense/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "mynRZePChmLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb30d595-e6b6-461b-d0d4-e90a33216429",
        "id": "I7XmGROwhmLt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_dataset_path = os.path.join(basepath, 'dataset/Pipeline_train_and_test/train-real-dataset-area/')\n",
        "image_test_file = os.listdir(train_real_dataset_path)\n",
        "path_test_image = train_real_dataset_path"
      ],
      "metadata": {
        "id": "X-Q2jNBXhmLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_TRAIN[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_TRAIN_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_TRAIN_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_TRAIN_{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61a471d-8c6e-4024-9f96-8285c101aef8",
        "id": "4Q9Kyy5_hmLt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_cp-0240.hdf5:  0.11363636363636363\n",
            "ACC_TRAIN_cp-0240.hdf5:  0.8080808080808081\n",
            "letter ACC_TRAIN_cp-0240.hdf5:  0.8720379146919431\n",
            "CER_TRAIN_cp-0260.hdf5:  0.010101010101010102\n",
            "ACC_TRAIN_cp-0260.hdf5:  0.9797979797979798\n",
            "letter ACC_TRAIN_cp-0260.hdf5:  0.9809523809523809\n",
            "CER_TRAIN_cp-0220.hdf5:  0.4983164983164985\n",
            "ACC_TRAIN_cp-0220.hdf5:  0.2828282828282828\n",
            "letter ACC_TRAIN_cp-0220.hdf5:  0.46919431279620855\n",
            "CER_TRAIN_cp-0280.hdf5:  0.015151515151515152\n",
            "ACC_TRAIN_cp-0280.hdf5:  0.9696969696969697\n",
            "letter ACC_TRAIN_cp-0280.hdf5:  0.9714285714285714\n",
            "CER_TRAIN_cp-0300.hdf5:  0.0\n",
            "ACC_TRAIN_cp-0300.hdf5:  1.0\n",
            "letter ACC_TRAIN_cp-0300.hdf5:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOvXID1bhmLt",
        "outputId": "2f6f6a8c-352c-45fd-88f5-a15fde2230a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.4983164983164985,\n",
              " 'cp-0240': 0.11363636363636363,\n",
              " 'cp-0260': 0.010101010101010102,\n",
              " 'cp-0280': 0.015151515151515152,\n",
              " 'cp-0300': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result val_image**"
      ],
      "metadata": {
        "id": "2uF1ShClhmLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_5_freeze35layer_fullfreezeuntildense/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "axIqEYW6hmLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e936a099-cea2-47e7-9850-4142c9f6e451",
        "id": "Y70OBunZhmLu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_dataset_path = os.path.join(basepath, 'dataset/Pipeline_train_and_test/val_real_dataset/')\n",
        "image_test_file = os.listdir(test_real_dataset_path)\n",
        "path_test_image = test_real_dataset_path"
      ],
      "metadata": {
        "id": "fwiQHseLhmLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_VAL[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_VAL_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_VAL_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_VAL{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648d146b-b2c2-4e43-9d32-b4d01739f7ac",
        "id": "UKXXVY2shmLu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_cp-0240.hdf5:  0.6180555555555556\n",
            "ACC_VAL_cp-0240.hdf5:  0.16666666666666666\n",
            "letter ACC_VALcp-0240.hdf5:  0.3333333333333333\n",
            "CER_VAL_cp-0260.hdf5:  0.4930555555555555\n",
            "ACC_VAL_cp-0260.hdf5:  0.3333333333333333\n",
            "letter ACC_VALcp-0260.hdf5:  0.41935483870967744\n",
            "CER_VAL_cp-0220.hdf5:  0.8472222222222222\n",
            "ACC_VAL_cp-0220.hdf5:  0.0\n",
            "letter ACC_VALcp-0220.hdf5:  0.07142857142857142\n",
            "CER_VAL_cp-0280.hdf5:  0.47222222222222215\n",
            "ACC_VAL_cp-0280.hdf5:  0.3333333333333333\n",
            "letter ACC_VALcp-0280.hdf5:  0.45161290322580644\n",
            "CER_VAL_cp-0300.hdf5:  0.47222222222222215\n",
            "ACC_VAL_cp-0300.hdf5:  0.3333333333333333\n",
            "letter ACC_VALcp-0300.hdf5:  0.4482758620689655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbjVEs6JhmLu",
        "outputId": "1e2ebed1-9adb-4f15-82f6-eeee955aa1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.8472222222222222,\n",
              " 'cp-0240': 0.6180555555555556,\n",
              " 'cp-0260': 0.4930555555555555,\n",
              " 'cp-0280': 0.47222222222222215,\n",
              " 'cp-0300': 0.47222222222222215}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lưu kết quả các checkpoint trên toàn bộ tập dữ liệu train và val**"
      ],
      "metadata": {
        "id": "KQJ0cPWchmLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "d1 = CER_CHECKPOINT_TRAIN\n",
        "d2 = CER_CHECKPOINT_VAL\n",
        "\n",
        "csv_columns = ['cp-0220', 'cp-0240', 'cp-0260', 'cp-0280', 'cp-0300']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_freeze35layers_freezeCRNN.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "QKi6g-CghmLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECK CP100 CHO TỪNG CLASS RIÊNG BIỆT TRONG TẬP DỮ LIỆU TRAIN VÀ VAL**"
      ],
      "metadata": {
        "id": "DI2BfRcxhmLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/train_real_dataset_classify/'\n",
        "train_real_classify_folder = os.listdir(train_real_classify_path)\n",
        "len(train_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b45db1-312c-413c-a3d7-9f2655c714ab",
        "id": "jS0J4s8shmLv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = []\n",
        "values = []\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  keys.append(folder)\n",
        "  values.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "qMVzD0q1hmLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys, values))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f40d93-e1b1-4992-df6f-d48960c96f1f",
        "id": "7SG1bmdHhmLv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 5,\n",
              " '三重': 1,\n",
              " '京': 1,\n",
              " '京都': 14,\n",
              " '八戸': 1,\n",
              " '八王子': 1,\n",
              " '千葉': 3,\n",
              " '名古屋': 2,\n",
              " '和歌山': 1,\n",
              " '和泉': 2,\n",
              " '品川': 5,\n",
              " '多摩': 3,\n",
              " '大宮': 2,\n",
              " '大阪': 7,\n",
              " '奈良': 2,\n",
              " '姫路': 2,\n",
              " '宇都宮': 1,\n",
              " '宮城': 1,\n",
              " '富山': 1,\n",
              " '山梨': 1,\n",
              " '岡山': 1,\n",
              " '川崎': 1,\n",
              " '所沢': 2,\n",
              " '春日部': 1,\n",
              " '横浜': 4,\n",
              " '水戸': 2,\n",
              " '沖': 1,\n",
              " '沼津': 1,\n",
              " '滋賀': 3,\n",
              " '熊谷': 1,\n",
              " '相模': 5,\n",
              " '神戸': 6,\n",
              " '練馬': 1,\n",
              " '群馬': 4,\n",
              " '習志野': 3,\n",
              " '足立': 4,\n",
              " '長野': 1,\n",
              " '静岡': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff369724-73ba-408c-ad60-b096219a615d",
        "id": "kUJ3w1fshmLv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ',\n",
              " '三重',\n",
              " '京',\n",
              " '京都',\n",
              " '八戸',\n",
              " '八王子',\n",
              " '千葉',\n",
              " '名古屋',\n",
              " '和歌山',\n",
              " '和泉',\n",
              " '品川',\n",
              " '多摩',\n",
              " '大宮',\n",
              " '大阪',\n",
              " '奈良',\n",
              " '姫路',\n",
              " '宇都宮',\n",
              " '宮城',\n",
              " '富山',\n",
              " '山梨',\n",
              " '岡山',\n",
              " '川崎',\n",
              " '所沢',\n",
              " '春日部',\n",
              " '横浜',\n",
              " '水戸',\n",
              " '沖',\n",
              " '沼津',\n",
              " '滋賀',\n",
              " '熊谷',\n",
              " '相模',\n",
              " '神戸',\n",
              " '練馬',\n",
              " '群馬',\n",
              " '習志野',\n",
              " '足立',\n",
              " '長野',\n",
              " '静岡']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/val_real_dataset_classify/'\n",
        "val_real_classify_folder = os.listdir(val_real_classify_path)\n",
        "len(val_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dbeb1b-c54f-462e-f9a2-8ecfe44f2dc9",
        "id": "y03UC0hRhmLv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val = []\n",
        "values_val = []\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  keys_val.append(folder)\n",
        "  values_val.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "Pm-XXj2yhmLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys_val, values_val))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd16da9-1c1e-481a-c806-a37449117911",
        "id": "7Ck1-KCnhmLw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1,\n",
              " '京都': 2,\n",
              " '八王子': 1,\n",
              " '名古屋': 1,\n",
              " '多摩': 1,\n",
              " '大阪': 1,\n",
              " '春日部': 1,\n",
              " '練馬': 2,\n",
              " '群馬': 1,\n",
              " '足立': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74556e1-7dcf-4af6-906c-97b5cfdaad06",
        "id": "UKjpBnX_hmLw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ', '京都', '八王子', '名古屋', '多摩', '大阪', '春日部', '練馬', '群馬', '足立']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "shpcfmXLhmLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  if folder in keys_val:\n",
        "    print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "    dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a0a3bf-420a-4735-b7ce-0e3a224f0685",
        "id": "TttZFdL4hmLw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6dbb16-b783-4236-f9eb-db8964f95375",
        "id": "DQRGmwW8hmLw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八王子': 0.3333333333333333,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '多摩': 0.0,\n",
              " '大阪': 0.0,\n",
              " '春日部': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '足立': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST 16032022 - TEST FULL TẬP TRAIN CHO CÁC CLASS Ở CP120\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # if folder in keys_val:\n",
        "  print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5e0ff-2025-4c69-eb0a-6991c1f569fe",
        "id": "snRzpKaphmLx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_三重:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_千葉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_和歌山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_和泉:  0.25\n",
            "CER_TRAIN_FOR_CLASS_品川:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_奈良:  0.0\n",
            "CER_TRAIN_FOR_CLASS_姫路:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宇都宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宮城:  0.0\n",
            "CER_TRAIN_FOR_CLASS_富山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_山梨:  0.0\n",
            "CER_TRAIN_FOR_CLASS_岡山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_川崎:  0.0\n",
            "CER_TRAIN_FOR_CLASS_所沢:  0.5\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_横浜:  0.0\n",
            "CER_TRAIN_FOR_CLASS_水戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沖:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沼津:  0.0\n",
            "CER_TRAIN_FOR_CLASS_滋賀:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_熊谷:  1.0\n",
            "CER_TRAIN_FOR_CLASS_相模:  0.0\n",
            "CER_TRAIN_FOR_CLASS_神戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_習志野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n",
            "CER_TRAIN_FOR_CLASS_長野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_静岡:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c48e83b-7e52-4580-b966-eb7e40fd389d",
        "id": "dT3QfK9ZhmLx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '三重': 0.0,\n",
              " '京': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八戸': 0.0,\n",
              " '八王子': 0.3333333333333333,\n",
              " '千葉': 0.0,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '和歌山': 0.0,\n",
              " '和泉': 0.25,\n",
              " '品川': 0.0,\n",
              " '多摩': 0.0,\n",
              " '大宮': 0.0,\n",
              " '大阪': 0.0,\n",
              " '奈良': 0.0,\n",
              " '姫路': 0.0,\n",
              " '宇都宮': 0.0,\n",
              " '宮城': 0.0,\n",
              " '富山': 0.0,\n",
              " '山梨': 0.0,\n",
              " '岡山': 0.0,\n",
              " '川崎': 0.0,\n",
              " '所沢': 0.5,\n",
              " '春日部': 0.0,\n",
              " '横浜': 0.0,\n",
              " '水戸': 0.0,\n",
              " '沖': 0.0,\n",
              " '沼津': 0.0,\n",
              " '滋賀': 0.16666666666666666,\n",
              " '熊谷': 1.0,\n",
              " '相模': 0.0,\n",
              " '神戸': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '習志野': 0.0,\n",
              " '足立': 0.0,\n",
              " '長野': 0.0,\n",
              " '静岡': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qfM1cSjIhmLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chạy kết quả trên từng class riêng biệt trên tập val, cụ thể là CP100**"
      ],
      "metadata": {
        "id": "OTXqlA2thmLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "cT_74jRyhmLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid = {}\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS.append(cer_rate)\n",
        "  dict_val_for_valid[str(folder)] = float(cer_rate)\n",
        "  print(\"CER_VAL_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  # print(\"ACC_VAL_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc85d35-9cf1-45e4-e67e-a85373b45105",
        "id": "D_sHWtsJhmLx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_FOR_CLASS_名古屋:  1.0\n",
            "CER_VAL_FOR_CLASS_なにわ:  1.0\n",
            "CER_VAL_FOR_CLASS_京都:  0.25\n",
            "CER_VAL_FOR_CLASS_八王子:  1.0\n",
            "CER_VAL_FOR_CLASS_大阪:  0.5\n",
            "CER_VAL_FOR_CLASS_多摩:  1.0\n",
            "CER_VAL_FOR_CLASS_群馬:  1.0\n",
            "CER_VAL_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_VAL_FOR_CLASS_練馬:  0.75\n",
            "CER_VAL_FOR_CLASS_足立:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7c94ac-1314-41d5-b95f-269cb6e21c6a",
        "id": "RDkLCPbIhmLy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1.0,\n",
              " '京都': 0.25,\n",
              " '八王子': 1.0,\n",
              " '名古屋': 1.0,\n",
              " '多摩': 1.0,\n",
              " '大阪': 0.5,\n",
              " '春日部': 0.3333333333333333,\n",
              " '練馬': 0.75,\n",
              " '群馬': 1.0,\n",
              " '足立': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tzd4rMdghmLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING18032022_FREEZE_LAYERS"
      ],
      "metadata": {
        "id": "NZiuqmhaoVBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING_FREEZE25LAYERS_FREEZECNN\n",
        "\n"
      ],
      "metadata": {
        "id": "QM_hTWEWoVBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result train_image**"
      ],
      "metadata": {
        "id": "4HzPc_mJoVBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_6_freeze25layers_freezeCNN_with_full_data/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "L_8t6LIfoVBs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c74e94-e762-4a03-a37b-885823b3ccf3",
        "id": "NQTZlEUpoVBt"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_dataset_path = os.path.join(basepath, 'dataset/region_license_plate_train_png/')\n",
        "image_test_file = os.listdir(train_real_dataset_path)\n",
        "path_test_image = train_real_dataset_path"
      ],
      "metadata": {
        "id": "Y68kBiqKoVBt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_TRAIN[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_TRAIN_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_TRAIN_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_TRAIN_{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d04c61-098d-4531-d128-b3cb2268230b",
        "id": "qaDnKND9oVBu"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_cp-0260.hdf5:  0.0010964912280701754\n",
            "ACC_TRAIN_cp-0260.hdf5:  0.9967105263157895\n",
            "letter ACC_TRAIN_cp-0260.hdf5:  0.9953703703703703\n",
            "CER_TRAIN_cp-0280.hdf5:  0.0021929824561403508\n",
            "ACC_TRAIN_cp-0280.hdf5:  0.9967105263157895\n",
            "letter ACC_TRAIN_cp-0280.hdf5:  0.9953703703703703\n",
            "CER_TRAIN_cp-0300.hdf5:  0.0010964912280701754\n",
            "ACC_TRAIN_cp-0300.hdf5:  0.9967105263157895\n",
            "letter ACC_TRAIN_cp-0300.hdf5:  0.9953703703703703\n",
            "CER_TRAIN_cp-0220.hdf5:  0.5427631578947368\n",
            "ACC_TRAIN_cp-0220.hdf5:  0.18092105263157895\n",
            "letter ACC_TRAIN_cp-0220.hdf5:  0.3282208588957055\n",
            "CER_TRAIN_cp-0240.hdf5:  0.013157894736842105\n",
            "ACC_TRAIN_cp-0240.hdf5:  0.9736842105263158\n",
            "letter ACC_TRAIN_cp-0240.hdf5:  0.9799382716049383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a673787-bc67-49e0-b16c-c3521a95e6f6",
        "id": "GymXqI6IoVBu"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.5427631578947368,\n",
              " 'cp-0240': 0.013157894736842105,\n",
              " 'cp-0260': 0.0010964912280701754,\n",
              " 'cp-0280': 0.0021929824561403508,\n",
              " 'cp-0300': 0.0010964912280701754}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result val_image**"
      ],
      "metadata": {
        "id": "70VA8GT1oVBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_6_freeze25layers_freezeCNN_with_full_data/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "o8dcijvGoVBv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fef5e20-3cc4-4397-dbea-9fd0a5851391",
        "id": "DgyPIgQAoVBv"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_dataset_path = os.path.join(basepath, 'dataset/region_licens_plate_val_png/')\n",
        "image_test_file = os.listdir(test_real_dataset_path)\n",
        "path_test_image = test_real_dataset_path"
      ],
      "metadata": {
        "id": "38FQvSQtoVBv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_VAL[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_VAL_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_VAL_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_VAL{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeacaca3-7799-4791-f1ac-c62ada6d913e",
        "id": "cCD21i2yoVBv"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_cp-0260.hdf5:  0.22149122807017552\n",
            "ACC_VAL_cp-0260.hdf5:  0.6710526315789473\n",
            "letter ACC_VALcp-0260.hdf5:  0.7134146341463414\n",
            "CER_VAL_cp-0280.hdf5:  0.1425438596491228\n",
            "ACC_VAL_cp-0280.hdf5:  0.75\n",
            "letter ACC_VALcp-0280.hdf5:  0.7926829268292683\n",
            "CER_VAL_cp-0300.hdf5:  0.10964912280701755\n",
            "ACC_VAL_cp-0300.hdf5:  0.8157894736842105\n",
            "letter ACC_VALcp-0300.hdf5:  0.845679012345679\n",
            "CER_VAL_cp-0220.hdf5:  0.7434210526315791\n",
            "ACC_VAL_cp-0220.hdf5:  0.06578947368421052\n",
            "letter ACC_VALcp-0220.hdf5:  0.15757575757575756\n",
            "CER_VAL_cp-0240.hdf5:  0.30701754385964913\n",
            "ACC_VAL_cp-0240.hdf5:  0.5263157894736842\n",
            "letter ACC_VALcp-0240.hdf5:  0.6204819277108434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefbcdf0-f28a-4d9b-c537-dd5c69b20b14",
        "id": "ruB0NigVoVBw"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.7434210526315791,\n",
              " 'cp-0240': 0.30701754385964913,\n",
              " 'cp-0260': 0.22149122807017552,\n",
              " 'cp-0280': 0.1425438596491228,\n",
              " 'cp-0300': 0.10964912280701755}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lưu kết quả các checkpoint trên toàn bộ tập dữ liệu train và val**"
      ],
      "metadata": {
        "id": "d1cQFAJ5oVBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "HEADER = ['CP20', 'CP40', 'CP60', 'CP80', 'CP100', 'CP120', 'CP140', 'CP160', 'CP180', 'CP200']\n",
        "DATA = [\n",
        "        CER_CHECKPOINT_TRAIN,\n",
        "        CER_CHECKPOINT_VAL,\n",
        "]\n",
        "\n",
        "with open('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/result.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    writer.writerow(HEADER)\n",
        "\n",
        "    writer.writerows(DATA)"
      ],
      "metadata": {
        "id": "avcUxBLPoVBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "d1 = CER_CHECKPOINT_TRAIN\n",
        "d2 = CER_CHECKPOINT_VAL\n",
        "\n",
        "csv_columns = ['cp-0220', 'cp-0240', 'cp-0260', 'cp-0280', 'cp-0300']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_freeze25layers_freezeCNN_18032022.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "Lv6WrqFFoVBx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECK CP260 CHO TỪNG CLASS RIÊNG BIỆT TRONG TẬP DỮ LIỆU TRAIN**"
      ],
      "metadata": {
        "id": "At6XkPLsoVBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/train_real_dataset_classify/'\n",
        "train_real_classify_folder = os.listdir(train_real_classify_path)\n",
        "len(train_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eed8346-4445-4874-ede9-02bc491c89ed",
        "id": "poVpB5UPoVBx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = []\n",
        "values = []\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  keys.append(folder)\n",
        "  values.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "vTsfRhF4oVBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_train = dict(zip(keys, values))\n",
        "dictionary_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664b41f2-0216-40b8-dc1b-ff635ccd5114",
        "id": "JHZsDhS7oVBy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 5,\n",
              " '三重': 1,\n",
              " '京': 1,\n",
              " '京都': 14,\n",
              " '八戸': 1,\n",
              " '八王子': 1,\n",
              " '千葉': 3,\n",
              " '名古屋': 2,\n",
              " '和歌山': 1,\n",
              " '和泉': 2,\n",
              " '品川': 5,\n",
              " '多摩': 3,\n",
              " '大宮': 2,\n",
              " '大阪': 7,\n",
              " '奈良': 2,\n",
              " '姫路': 2,\n",
              " '宇都宮': 1,\n",
              " '宮城': 1,\n",
              " '富山': 1,\n",
              " '山梨': 1,\n",
              " '岡山': 1,\n",
              " '川崎': 1,\n",
              " '所沢': 2,\n",
              " '春日部': 1,\n",
              " '横浜': 4,\n",
              " '水戸': 2,\n",
              " '沖': 1,\n",
              " '沼津': 1,\n",
              " '滋賀': 3,\n",
              " '熊谷': 1,\n",
              " '相模': 5,\n",
              " '神戸': 6,\n",
              " '練馬': 1,\n",
              " '群馬': 4,\n",
              " '習志野': 3,\n",
              " '足立': 4,\n",
              " '長野': 1,\n",
              " '静岡': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5c39d7-0d9a-4409-8af0-f6ab59671e90",
        "id": "BaiULjmjoVBy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ',\n",
              " '三重',\n",
              " '京',\n",
              " '京都',\n",
              " '八戸',\n",
              " '八王子',\n",
              " '千葉',\n",
              " '名古屋',\n",
              " '和歌山',\n",
              " '和泉',\n",
              " '品川',\n",
              " '多摩',\n",
              " '大宮',\n",
              " '大阪',\n",
              " '奈良',\n",
              " '姫路',\n",
              " '宇都宮',\n",
              " '宮城',\n",
              " '富山',\n",
              " '山梨',\n",
              " '岡山',\n",
              " '川崎',\n",
              " '所沢',\n",
              " '春日部',\n",
              " '横浜',\n",
              " '水戸',\n",
              " '沖',\n",
              " '沼津',\n",
              " '滋賀',\n",
              " '熊谷',\n",
              " '相模',\n",
              " '神戸',\n",
              " '練馬',\n",
              " '群馬',\n",
              " '習志野',\n",
              " '足立',\n",
              " '長野',\n",
              " '静岡']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/val_real_dataset_classify/'\n",
        "val_real_classify_folder = os.listdir(val_real_classify_path)\n",
        "len(val_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473ca2da-9826-4ea9-d1d4-6dd80aedb7fa",
        "id": "uhnCoyrXoVBy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val = []\n",
        "values_val = []\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  keys_val.append(folder)\n",
        "  values_val.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "vyWwzU5WoVBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_val = dict(zip(keys_val, values_val))\n",
        "dictionary_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6d86f8-ce25-44b1-9f01-cfdbb749d568",
        "id": "nqDJUXbJoVBz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1,\n",
              " '京都': 2,\n",
              " '八王子': 1,\n",
              " '名古屋': 1,\n",
              " '多摩': 1,\n",
              " '大阪': 1,\n",
              " '春日部': 1,\n",
              " '練馬': 2,\n",
              " '群馬': 1,\n",
              " '足立': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c2ef32-57f8-47f8-93fb-fa23e351302f",
        "id": "HudRqKtNoVBz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ', '京都', '八王子', '名古屋', '多摩', '大阪', '春日部', '練馬', '群馬', '足立']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_3_freeze25layer_freezeCNN/cp-0260.hdf5')"
      ],
      "metadata": {
        "id": "f2y53HxjoVBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check class only in test and log value of train\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  if folder in keys_val:\n",
        "    print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "    dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd43d98-8d8c-46d6-a2a5-ad53c43f9875",
        "id": "J0NQ4V_xoVBz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.023809523809523808\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.125\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37b2eca-b8c0-4d99-d594-9e5cb55b7c03",
        "id": "PRnbGfBSoVB0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '京都': 0.023809523809523808,\n",
              " '八王子': 0.0,\n",
              " '名古屋': 0.125,\n",
              " '多摩': 0.16666666666666666,\n",
              " '大阪': 0.0,\n",
              " '春日部': 0.3333333333333333,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.0,\n",
              " '足立': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST 17032022 - TEST FULL TẬP TRAIN CHO CÁC CLASS Ở CP260\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # if folder in keys_val:\n",
        "  print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98784b5-c7be-4f39-80a8-7b4989cfbde8",
        "id": "c-5u_NWOoVB0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_三重:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.023809523809523808\n",
            "CER_TRAIN_FOR_CLASS_八戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.0\n",
            "CER_TRAIN_FOR_CLASS_千葉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.125\n",
            "CER_TRAIN_FOR_CLASS_和歌山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_和泉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_品川:  0.1\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_奈良:  0.0\n",
            "CER_TRAIN_FOR_CLASS_姫路:  0.25\n",
            "CER_TRAIN_FOR_CLASS_宇都宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宮城:  0.5\n",
            "CER_TRAIN_FOR_CLASS_富山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_山梨:  0.5\n",
            "CER_TRAIN_FOR_CLASS_岡山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_川崎:  0.0\n",
            "CER_TRAIN_FOR_CLASS_所沢:  0.25\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_横浜:  0.125\n",
            "CER_TRAIN_FOR_CLASS_水戸:  0.25\n",
            "CER_TRAIN_FOR_CLASS_沖:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沼津:  0.5\n",
            "CER_TRAIN_FOR_CLASS_滋賀:  0.0\n",
            "CER_TRAIN_FOR_CLASS_熊谷:  0.5\n",
            "CER_TRAIN_FOR_CLASS_相模:  0.0\n",
            "CER_TRAIN_FOR_CLASS_神戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_習志野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n",
            "CER_TRAIN_FOR_CLASS_長野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_静岡:  0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8191b25-7b5f-4ab7-bd1a-383df1176f7c",
        "id": "3d-dg2X-oVB0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '三重': 0.0,\n",
              " '京': 0.0,\n",
              " '京都': 0.023809523809523808,\n",
              " '八戸': 0.0,\n",
              " '八王子': 0.0,\n",
              " '千葉': 0.0,\n",
              " '名古屋': 0.125,\n",
              " '和歌山': 0.0,\n",
              " '和泉': 0.0,\n",
              " '品川': 0.1,\n",
              " '多摩': 0.16666666666666666,\n",
              " '大宮': 0.0,\n",
              " '大阪': 0.0,\n",
              " '奈良': 0.0,\n",
              " '姫路': 0.25,\n",
              " '宇都宮': 0.0,\n",
              " '宮城': 0.5,\n",
              " '富山': 0.0,\n",
              " '山梨': 0.5,\n",
              " '岡山': 0.0,\n",
              " '川崎': 0.0,\n",
              " '所沢': 0.25,\n",
              " '春日部': 0.3333333333333333,\n",
              " '横浜': 0.125,\n",
              " '水戸': 0.25,\n",
              " '沖': 0.0,\n",
              " '沼津': 0.5,\n",
              " '滋賀': 0.0,\n",
              " '熊谷': 0.5,\n",
              " '相模': 0.0,\n",
              " '神戸': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.0,\n",
              " '習志野': 0.0,\n",
              " '足立': 0.0,\n",
              " '長野': 0.0,\n",
              " '静岡': 0.25}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6Y5_T_r8oVB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chạy kết quả trên từng class riêng biệt trên tập val, cụ thể là CP260**"
      ],
      "metadata": {
        "id": "XFcBdS3foVB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_3_freeze25layer_freezeCNN/cp-0260.hdf5')"
      ],
      "metadata": {
        "id": "oik_TTfmoVB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid = {}\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS.append(cer_rate)\n",
        "  dict_val_for_valid[str(folder)] = float(cer_rate)\n",
        "  print(\"CER_VAL_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  # print(\"ACC_VAL_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22cb96d8-21f5-4864-8458-a85e7c8bfc1b",
        "id": "pIt0PJDzoVB0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_FOR_CLASS_なにわ:  1.0\n",
            "CER_VAL_FOR_CLASS_京都:  0.0\n",
            "CER_VAL_FOR_CLASS_八王子:  1.0\n",
            "CER_VAL_FOR_CLASS_名古屋:  1.0\n",
            "CER_VAL_FOR_CLASS_多摩:  0.5\n",
            "CER_VAL_FOR_CLASS_大阪:  0.5\n",
            "CER_VAL_FOR_CLASS_春日部:  1.0\n",
            "CER_VAL_FOR_CLASS_練馬:  0.75\n",
            "CER_VAL_FOR_CLASS_群馬:  1.0\n",
            "CER_VAL_FOR_CLASS_足立:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97962870-ca2a-4af4-ebf3-d1063411e206",
        "id": "ZaWKWTMBoVB0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1.0,\n",
              " '京都': 0.0,\n",
              " '八王子': 1.0,\n",
              " '名古屋': 1.0,\n",
              " '多摩': 0.5,\n",
              " '大阪': 0.5,\n",
              " '春日部': 1.0,\n",
              " '練馬': 0.75,\n",
              " '群馬': 1.0,\n",
              " '足立': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lưu kết quả** "
      ],
      "metadata": {
        "id": "MQpT8RD4oVB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "d1 = dict_val_for_train\n",
        "d2 = dict_val_for_valid\n",
        "\n",
        "csv_columns = ['なにわ',\n",
        " '三重',\n",
        " '京',\n",
        " '京都',\n",
        " '八戸',\n",
        " '八王子',\n",
        " '千葉',\n",
        " '名古屋',\n",
        " '和歌山',\n",
        " '和泉',\n",
        " '品川',\n",
        " '多摩',\n",
        " '大宮',\n",
        " '大阪',\n",
        " '奈良',\n",
        " '姫路',\n",
        " '宇都宮',\n",
        " '宮城',\n",
        " '富山',\n",
        " '山梨',\n",
        " '岡山',\n",
        " '川崎',\n",
        " '所沢',\n",
        " '春日部',\n",
        " '横浜',\n",
        " '水戸',\n",
        " '沖',\n",
        " '沼津',\n",
        " '滋賀',\n",
        " '熊谷',\n",
        " '相模',\n",
        " '神戸',\n",
        " '練馬',\n",
        " '群馬',\n",
        " '習志野',\n",
        " '足立',\n",
        " '長野',\n",
        " '静岡']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_freeze25layers_freezeCNN_specify_for_class.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "b2OC1afAoVB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "d1 = dictionary_train \n",
        "d2 = dictionary_val\n",
        "csv_columns = ['なにわ',\n",
        " '三重',\n",
        " '京',\n",
        " '京都',\n",
        " '八戸',\n",
        " '八王子',\n",
        " '千葉',\n",
        " '名古屋',\n",
        " '和歌山',\n",
        " '和泉',\n",
        " '品川',\n",
        " '多摩',\n",
        " '大宮',\n",
        " '大阪',\n",
        " '奈良',\n",
        " '姫路',\n",
        " '宇都宮',\n",
        " '宮城',\n",
        " '富山',\n",
        " '山梨',\n",
        " '岡山',\n",
        " '川崎',\n",
        " '所沢',\n",
        " '春日部',\n",
        " '横浜',\n",
        " '水戸',\n",
        " '沖',\n",
        " '沼津',\n",
        " '滋賀',\n",
        " '熊谷',\n",
        " '相模',\n",
        " '神戸',\n",
        " '練馬',\n",
        " '群馬',\n",
        " '習志野',\n",
        " '足立',\n",
        " '長野',\n",
        " '静岡']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/samples_in_every_class.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "VtVY--XQoVB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING_FREEZE31LAYERS_FREEZE_ONEPART_OF_RNN\n",
        "\n"
      ],
      "metadata": {
        "id": "HYvLZyWDoVB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result train_image**"
      ],
      "metadata": {
        "id": "dkcVeiFToVB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_7_freeze31layers_freeze_one_part_of_RNN_full_data/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "guXYa6fmoVB1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3ce36e-13b3-4d2e-d931-7f2ffd14c662",
        "id": "pKOdUHDGoVB1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_dataset_path = os.path.join(basepath, 'dataset/region_license_plate_train_png/')\n",
        "image_test_file = os.listdir(train_real_dataset_path)\n",
        "path_test_image = train_real_dataset_path"
      ],
      "metadata": {
        "id": "c7Ey-xFUoVB1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_TRAIN[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_TRAIN_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_TRAIN_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_TRAIN_{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53781c3e-07f0-436c-a44b-963090cffb0a",
        "id": "g7pC9eGsoVB2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_cp-0240.hdf5:  0.00712719298245614\n",
            "ACC_TRAIN_cp-0240.hdf5:  0.9901315789473685\n",
            "letter ACC_TRAIN_cp-0240.hdf5:  0.9922839506172839\n",
            "CER_TRAIN_cp-0260.hdf5:  0.005482456140350877\n",
            "ACC_TRAIN_cp-0260.hdf5:  0.993421052631579\n",
            "letter ACC_TRAIN_cp-0260.hdf5:  0.9953703703703703\n",
            "CER_TRAIN_cp-0280.hdf5:  0.0021929824561403508\n",
            "ACC_TRAIN_cp-0280.hdf5:  0.9967105263157895\n",
            "letter ACC_TRAIN_cp-0280.hdf5:  0.9969135802469136\n",
            "CER_TRAIN_cp-0300.hdf5:  0.0021929824561403508\n",
            "ACC_TRAIN_cp-0300.hdf5:  0.9967105263157895\n",
            "letter ACC_TRAIN_cp-0300.hdf5:  0.9969135802469136\n",
            "CER_TRAIN_cp-0220.hdf5:  0.3834978070175438\n",
            "ACC_TRAIN_cp-0220.hdf5:  0.3717105263157895\n",
            "letter ACC_TRAIN_cp-0220.hdf5:  0.49390243902439024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d3cc62-9862-4b3f-cd5d-12172c069f78",
        "id": "0xcM1U7WoVB2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.3834978070175438,\n",
              " 'cp-0240': 0.00712719298245614,\n",
              " 'cp-0260': 0.005482456140350877,\n",
              " 'cp-0280': 0.0021929824561403508,\n",
              " 'cp-0300': 0.0021929824561403508}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result val_image**"
      ],
      "metadata": {
        "id": "XuOGrwzuoVB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_7_freeze31layers_freeze_one_part_of_RNN_full_data/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "ZUeqFNDDoVB2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d49d81-8620-4928-baac-7f1735b26c56",
        "id": "693BAO9ioVB2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_dataset_path = os.path.join(basepath, 'dataset/region_licens_plate_val_png/')\n",
        "image_test_file = os.listdir(test_real_dataset_path)\n",
        "path_test_image = test_real_dataset_path"
      ],
      "metadata": {
        "id": "8_KFzleZoVB2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_VAL[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_VAL_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_VAL_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_VAL{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63932dc6-089d-4b8a-b2df-8a80e0319dbc",
        "id": "ixRGmxhfoVB2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_cp-0240.hdf5:  0.2192982456140351\n",
            "ACC_VAL_cp-0240.hdf5:  0.6447368421052632\n",
            "letter ACC_VALcp-0240.hdf5:  0.7212121212121212\n",
            "CER_VAL_cp-0260.hdf5:  0.1513157894736842\n",
            "ACC_VAL_cp-0260.hdf5:  0.7763157894736842\n",
            "letter ACC_VALcp-0260.hdf5:  0.8024691358024691\n",
            "CER_VAL_cp-0280.hdf5:  0.12280701754385963\n",
            "ACC_VAL_cp-0280.hdf5:  0.8289473684210527\n",
            "letter ACC_VALcp-0280.hdf5:  0.8292682926829268\n",
            "CER_VAL_cp-0300.hdf5:  0.10087719298245613\n",
            "ACC_VAL_cp-0300.hdf5:  0.8552631578947368\n",
            "letter ACC_VALcp-0300.hdf5:  0.8641975308641975\n",
            "CER_VAL_cp-0220.hdf5:  0.6864035087719299\n",
            "ACC_VAL_cp-0220.hdf5:  0.09210526315789473\n",
            "letter ACC_VALcp-0220.hdf5:  0.19879518072289157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf27861b-9637-4e23-f874-bbeda835dbb2",
        "id": "wJxGDr3foVB3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.6864035087719299,\n",
              " 'cp-0240': 0.2192982456140351,\n",
              " 'cp-0260': 0.1513157894736842,\n",
              " 'cp-0280': 0.12280701754385963,\n",
              " 'cp-0300': 0.10087719298245613}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lưu kết quả các checkpoint trên toàn bộ tập dữ liệu train và val**"
      ],
      "metadata": {
        "id": "dtPyj1o9oVB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "d1 = CER_CHECKPOINT_TRAIN\n",
        "d2 = CER_CHECKPOINT_VAL\n",
        "\n",
        "csv_columns = ['cp-0220', 'cp-0240', 'cp-0260', 'cp-0280', 'cp-0300']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_freeze31layers_freeze_one_part_of_RNN_18032022_balancedata.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "tuOkuBF8oVB3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECK CP100 CHO TỪNG CLASS RIÊNG BIỆT TRONG TẬP DỮ LIỆU TRAIN VÀ VAL**"
      ],
      "metadata": {
        "id": "jhl1R6aJoVB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/train_real_dataset_classify/'\n",
        "train_real_classify_folder = os.listdir(train_real_classify_path)\n",
        "len(train_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b45db1-312c-413c-a3d7-9f2655c714ab",
        "id": "EaDxPJUfoVB3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = []\n",
        "values = []\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  keys.append(folder)\n",
        "  values.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "_YYryAg0oVB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys, values))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f40d93-e1b1-4992-df6f-d48960c96f1f",
        "id": "pshNHT9soVB3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 5,\n",
              " '三重': 1,\n",
              " '京': 1,\n",
              " '京都': 14,\n",
              " '八戸': 1,\n",
              " '八王子': 1,\n",
              " '千葉': 3,\n",
              " '名古屋': 2,\n",
              " '和歌山': 1,\n",
              " '和泉': 2,\n",
              " '品川': 5,\n",
              " '多摩': 3,\n",
              " '大宮': 2,\n",
              " '大阪': 7,\n",
              " '奈良': 2,\n",
              " '姫路': 2,\n",
              " '宇都宮': 1,\n",
              " '宮城': 1,\n",
              " '富山': 1,\n",
              " '山梨': 1,\n",
              " '岡山': 1,\n",
              " '川崎': 1,\n",
              " '所沢': 2,\n",
              " '春日部': 1,\n",
              " '横浜': 4,\n",
              " '水戸': 2,\n",
              " '沖': 1,\n",
              " '沼津': 1,\n",
              " '滋賀': 3,\n",
              " '熊谷': 1,\n",
              " '相模': 5,\n",
              " '神戸': 6,\n",
              " '練馬': 1,\n",
              " '群馬': 4,\n",
              " '習志野': 3,\n",
              " '足立': 4,\n",
              " '長野': 1,\n",
              " '静岡': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff369724-73ba-408c-ad60-b096219a615d",
        "id": "fJWLdJHaoVB3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ',\n",
              " '三重',\n",
              " '京',\n",
              " '京都',\n",
              " '八戸',\n",
              " '八王子',\n",
              " '千葉',\n",
              " '名古屋',\n",
              " '和歌山',\n",
              " '和泉',\n",
              " '品川',\n",
              " '多摩',\n",
              " '大宮',\n",
              " '大阪',\n",
              " '奈良',\n",
              " '姫路',\n",
              " '宇都宮',\n",
              " '宮城',\n",
              " '富山',\n",
              " '山梨',\n",
              " '岡山',\n",
              " '川崎',\n",
              " '所沢',\n",
              " '春日部',\n",
              " '横浜',\n",
              " '水戸',\n",
              " '沖',\n",
              " '沼津',\n",
              " '滋賀',\n",
              " '熊谷',\n",
              " '相模',\n",
              " '神戸',\n",
              " '練馬',\n",
              " '群馬',\n",
              " '習志野',\n",
              " '足立',\n",
              " '長野',\n",
              " '静岡']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/val_real_dataset_classify/'\n",
        "val_real_classify_folder = os.listdir(val_real_classify_path)\n",
        "len(val_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dbeb1b-c54f-462e-f9a2-8ecfe44f2dc9",
        "id": "ZKFD7vUOoVB4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val = []\n",
        "values_val = []\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  keys_val.append(folder)\n",
        "  values_val.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "Z13vCLw8oVB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys_val, values_val))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd16da9-1c1e-481a-c806-a37449117911",
        "id": "1h7o91N_oVB4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1,\n",
              " '京都': 2,\n",
              " '八王子': 1,\n",
              " '名古屋': 1,\n",
              " '多摩': 1,\n",
              " '大阪': 1,\n",
              " '春日部': 1,\n",
              " '練馬': 2,\n",
              " '群馬': 1,\n",
              " '足立': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74556e1-7dcf-4af6-906c-97b5cfdaad06",
        "id": "A-RFIt0joVB4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ', '京都', '八王子', '名古屋', '多摩', '大阪', '春日部', '練馬', '群馬', '足立']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "scg4kuvYoVB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  if folder in keys_val:\n",
        "    print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "    dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a0a3bf-420a-4735-b7ce-0e3a224f0685",
        "id": "WyH2TPi0oVB4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6dbb16-b783-4236-f9eb-db8964f95375",
        "id": "4_D98m_GoVB4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八王子': 0.3333333333333333,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '多摩': 0.0,\n",
              " '大阪': 0.0,\n",
              " '春日部': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '足立': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST 16032022 - TEST FULL TẬP TRAIN CHO CÁC CLASS Ở CP120\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # if folder in keys_val:\n",
        "  print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5e0ff-2025-4c69-eb0a-6991c1f569fe",
        "id": "Qj9VkR8joVB4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_三重:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_千葉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_和歌山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_和泉:  0.25\n",
            "CER_TRAIN_FOR_CLASS_品川:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_奈良:  0.0\n",
            "CER_TRAIN_FOR_CLASS_姫路:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宇都宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宮城:  0.0\n",
            "CER_TRAIN_FOR_CLASS_富山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_山梨:  0.0\n",
            "CER_TRAIN_FOR_CLASS_岡山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_川崎:  0.0\n",
            "CER_TRAIN_FOR_CLASS_所沢:  0.5\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_横浜:  0.0\n",
            "CER_TRAIN_FOR_CLASS_水戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沖:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沼津:  0.0\n",
            "CER_TRAIN_FOR_CLASS_滋賀:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_熊谷:  1.0\n",
            "CER_TRAIN_FOR_CLASS_相模:  0.0\n",
            "CER_TRAIN_FOR_CLASS_神戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_習志野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n",
            "CER_TRAIN_FOR_CLASS_長野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_静岡:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c48e83b-7e52-4580-b966-eb7e40fd389d",
        "id": "9OSsyAmaoVB5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '三重': 0.0,\n",
              " '京': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八戸': 0.0,\n",
              " '八王子': 0.3333333333333333,\n",
              " '千葉': 0.0,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '和歌山': 0.0,\n",
              " '和泉': 0.25,\n",
              " '品川': 0.0,\n",
              " '多摩': 0.0,\n",
              " '大宮': 0.0,\n",
              " '大阪': 0.0,\n",
              " '奈良': 0.0,\n",
              " '姫路': 0.0,\n",
              " '宇都宮': 0.0,\n",
              " '宮城': 0.0,\n",
              " '富山': 0.0,\n",
              " '山梨': 0.0,\n",
              " '岡山': 0.0,\n",
              " '川崎': 0.0,\n",
              " '所沢': 0.5,\n",
              " '春日部': 0.0,\n",
              " '横浜': 0.0,\n",
              " '水戸': 0.0,\n",
              " '沖': 0.0,\n",
              " '沼津': 0.0,\n",
              " '滋賀': 0.16666666666666666,\n",
              " '熊谷': 1.0,\n",
              " '相模': 0.0,\n",
              " '神戸': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '習志野': 0.0,\n",
              " '足立': 0.0,\n",
              " '長野': 0.0,\n",
              " '静岡': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PSmZBUhcoVB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chạy kết quả trên từng class riêng biệt trên tập val, cụ thể là CP100**"
      ],
      "metadata": {
        "id": "yn1GQSjOoVB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "iGz-NSAeoVB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid = {}\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS.append(cer_rate)\n",
        "  dict_val_for_valid[str(folder)] = float(cer_rate)\n",
        "  print(\"CER_VAL_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  # print(\"ACC_VAL_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc85d35-9cf1-45e4-e67e-a85373b45105",
        "id": "YUjQ5axWoVB5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_FOR_CLASS_名古屋:  1.0\n",
            "CER_VAL_FOR_CLASS_なにわ:  1.0\n",
            "CER_VAL_FOR_CLASS_京都:  0.25\n",
            "CER_VAL_FOR_CLASS_八王子:  1.0\n",
            "CER_VAL_FOR_CLASS_大阪:  0.5\n",
            "CER_VAL_FOR_CLASS_多摩:  1.0\n",
            "CER_VAL_FOR_CLASS_群馬:  1.0\n",
            "CER_VAL_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_VAL_FOR_CLASS_練馬:  0.75\n",
            "CER_VAL_FOR_CLASS_足立:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7c94ac-1314-41d5-b95f-269cb6e21c6a",
        "id": "l6A1BvLhoVB5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1.0,\n",
              " '京都': 0.25,\n",
              " '八王子': 1.0,\n",
              " '名古屋': 1.0,\n",
              " '多摩': 1.0,\n",
              " '大阪': 0.5,\n",
              " '春日部': 0.3333333333333333,\n",
              " '練馬': 0.75,\n",
              " '群馬': 1.0,\n",
              " '足立': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YFJVODjzoVB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING_FREEZE35LAYERS_FREEZECRNN\n",
        "\n"
      ],
      "metadata": {
        "id": "vePIkGPaoVB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result train_image**"
      ],
      "metadata": {
        "id": "Oymvlu55oVB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_8_freeze35layers_freezeCRNN_with_full_data/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "m5mysINXoVB6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc029c03-bc3e-407e-ae2f-520fee2016db",
        "id": "Rk2Q9A0DoVB6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_dataset_path = os.path.join(basepath, 'dataset/region_license_plate_train_png/')\n",
        "image_test_file = os.listdir(train_real_dataset_path)\n",
        "path_test_image = train_real_dataset_path"
      ],
      "metadata": {
        "id": "Mv00k5CDoVB6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_TRAIN[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_TRAIN_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_TRAIN_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_TRAIN_{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52489a77-d631-4260-80e4-bc4da0f89f0f",
        "id": "tp9M4FQYoVB6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_cp-0300.hdf5:  0.0010964912280701754\n",
            "ACC_TRAIN_cp-0300.hdf5:  0.9967105263157895\n",
            "letter ACC_TRAIN_cp-0300.hdf5:  0.9953703703703703\n",
            "CER_TRAIN_cp-0220.hdf5:  0.44517543859649106\n",
            "ACC_TRAIN_cp-0220.hdf5:  0.3026315789473684\n",
            "letter ACC_TRAIN_cp-0220.hdf5:  0.46788990825688076\n",
            "CER_TRAIN_cp-0240.hdf5:  0.06414473684210527\n",
            "ACC_TRAIN_cp-0240.hdf5:  0.8848684210526315\n",
            "letter ACC_TRAIN_cp-0240.hdf5:  0.9153846153846154\n",
            "CER_TRAIN_cp-0260.hdf5:  0.00712719298245614\n",
            "ACC_TRAIN_cp-0260.hdf5:  0.9868421052631579\n",
            "letter ACC_TRAIN_cp-0260.hdf5:  0.9891975308641975\n",
            "CER_TRAIN_cp-0280.hdf5:  0.0010964912280701754\n",
            "ACC_TRAIN_cp-0280.hdf5:  0.9967105263157895\n",
            "letter ACC_TRAIN_cp-0280.hdf5:  0.9953703703703703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_TRAIN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2461cbc7-f9ad-4eb1-e078-f386cbd6b87a",
        "id": "WScoqMeqoVB6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.44517543859649106,\n",
              " 'cp-0240': 0.06414473684210527,\n",
              " 'cp-0260': 0.00712719298245614,\n",
              " 'cp-0280': 0.0010964912280701754,\n",
              " 'cp-0300': 0.0010964912280701754}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check result val_image**"
      ],
      "metadata": {
        "id": "56A4ixeuoVB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(basepath, 'training_8_freeze35layers_freezeCRNN_with_full_data/')\n",
        "checkpoint_file = os.listdir(checkpoint_path)"
      ],
      "metadata": {
        "id": "Y_wyFDnUoVB6"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(checkpoint_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4824136-c202-42e5-b6f0-aaca6bbd1b3c",
        "id": "svXx3yC7oVB7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_dataset_path = os.path.join(basepath, 'dataset/region_licens_plate_val_png/')\n",
        "image_test_file = os.listdir(test_real_dataset_path)\n",
        "path_test_image = test_real_dataset_path"
      ],
      "metadata": {
        "id": "1ZLiydjEoVB7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL = {}\n",
        "for checkpoint in checkpoint_file:\n",
        "  path = checkpoint_path + checkpoint\n",
        "  model = get_Model(training=False)\n",
        "  model.load_weights(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  for image in image_test_file:\n",
        "      # choice = random.randint(0,9999)\n",
        "      path = path_test_image + image\n",
        "      \n",
        "      img_pred = process_image(path)\n",
        "      net_out_value = model.predict(img_pred)\n",
        "      pred_texts = decode_label(net_out_value)\n",
        "      newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "      # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "      string = ''\n",
        "      for j in range(3):\n",
        "          if image[j]>='0' and image[j]<='9':\n",
        "            continue\n",
        "          else:\n",
        "            string += image[j]\n",
        "      if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "      if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "      # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "      cer = edit_distance(newstr, string)\n",
        "      error = cer/max(len(newstr), len(string))\n",
        "      \n",
        "\n",
        "      for i in range(min(len(newstr), len(string))):\n",
        "      #ti = test_img[i][:-9]\n",
        "          if newstr[i] == string[i]:\n",
        "              letter_acc += 1\n",
        "      letter_total += max(len(newstr), len(string))\n",
        "      if newstr == string:\n",
        "          acc += 1\n",
        "      total += 1\n",
        "      sum_cer.append(error)\n",
        "  cer_rate = sum(sum_cer) / len(image_test_file)\n",
        "  CER_CHECKPOINT_VAL[str(checkpoint).split('.')[0]]=float(cer_rate)\n",
        "  print(\"CER_VAL_{}: \".format(str(checkpoint)),cer_rate)\n",
        "  print(\"ACC_VAL_{}: \".format(str(checkpoint)), acc / total)\n",
        "  print(\"letter ACC_VAL{}: \".format(str(checkpoint)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef5bd1a-a6ff-47e7-ddd2-2ae7fe7d2ee8",
        "id": "Ufuzn3UxoVB7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_cp-0300.hdf5:  0.14035087719298248\n",
            "ACC_VAL_cp-0300.hdf5:  0.7894736842105263\n",
            "letter ACC_VALcp-0300.hdf5:  0.8220858895705522\n",
            "CER_VAL_cp-0220.hdf5:  0.7192982456140351\n",
            "ACC_VAL_cp-0220.hdf5:  0.09210526315789473\n",
            "letter ACC_VALcp-0220.hdf5:  0.19642857142857142\n",
            "CER_VAL_cp-0240.hdf5:  0.37280701754385964\n",
            "ACC_VAL_cp-0240.hdf5:  0.4605263157894737\n",
            "letter ACC_VALcp-0240.hdf5:  0.572289156626506\n",
            "CER_VAL_cp-0260.hdf5:  0.18421052631578946\n",
            "ACC_VAL_cp-0260.hdf5:  0.7368421052631579\n",
            "letter ACC_VALcp-0260.hdf5:  0.7914110429447853\n",
            "CER_VAL_cp-0280.hdf5:  0.17982456140350878\n",
            "ACC_VAL_cp-0280.hdf5:  0.7105263157894737\n",
            "letter ACC_VALcp-0280.hdf5:  0.7852760736196319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CER_CHECKPOINT_VAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30bf997-c9ea-4cd6-868d-ba91e8842137",
        "id": "aWDCpH5DoVB7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cp-0220': 0.7192982456140351,\n",
              " 'cp-0240': 0.37280701754385964,\n",
              " 'cp-0260': 0.18421052631578946,\n",
              " 'cp-0280': 0.17982456140350878,\n",
              " 'cp-0300': 0.14035087719298248}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lưu kết quả các checkpoint trên toàn bộ tập dữ liệu train và val**"
      ],
      "metadata": {
        "id": "wIDm3NSYoVB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "d1 = CER_CHECKPOINT_TRAIN\n",
        "d2 = CER_CHECKPOINT_VAL\n",
        "\n",
        "csv_columns = ['cp-0220', 'cp-0240', 'cp-0260', 'cp-0280', 'cp-0300']\n",
        "\n",
        "with open('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/result_freeze35layers_freezeCRNN_18032022_balancedata.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "    wr = csv.DictWriter(f, fieldnames=csv_columns)\n",
        "    wr.writeheader()\n",
        "    wr.writerow(d1)\n",
        "    wr.writerow(d2)"
      ],
      "metadata": {
        "id": "JECB_fCHoVB7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECK CP100 CHO TỪNG CLASS RIÊNG BIỆT TRONG TẬP DỮ LIỆU TRAIN VÀ VAL**"
      ],
      "metadata": {
        "id": "ZPXicJIsoVB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/train_real_dataset_classify/'\n",
        "train_real_classify_folder = os.listdir(train_real_classify_path)\n",
        "len(train_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b45db1-312c-413c-a3d7-9f2655c714ab",
        "id": "MQBHJv2GoVB8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = []\n",
        "values = []\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  keys.append(folder)\n",
        "  values.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "7Gw-mGMjoVB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys, values))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f40d93-e1b1-4992-df6f-d48960c96f1f",
        "id": "BUhWEE-8oVB8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 5,\n",
              " '三重': 1,\n",
              " '京': 1,\n",
              " '京都': 14,\n",
              " '八戸': 1,\n",
              " '八王子': 1,\n",
              " '千葉': 3,\n",
              " '名古屋': 2,\n",
              " '和歌山': 1,\n",
              " '和泉': 2,\n",
              " '品川': 5,\n",
              " '多摩': 3,\n",
              " '大宮': 2,\n",
              " '大阪': 7,\n",
              " '奈良': 2,\n",
              " '姫路': 2,\n",
              " '宇都宮': 1,\n",
              " '宮城': 1,\n",
              " '富山': 1,\n",
              " '山梨': 1,\n",
              " '岡山': 1,\n",
              " '川崎': 1,\n",
              " '所沢': 2,\n",
              " '春日部': 1,\n",
              " '横浜': 4,\n",
              " '水戸': 2,\n",
              " '沖': 1,\n",
              " '沼津': 1,\n",
              " '滋賀': 3,\n",
              " '熊谷': 1,\n",
              " '相模': 5,\n",
              " '神戸': 6,\n",
              " '練馬': 1,\n",
              " '群馬': 4,\n",
              " '習志野': 3,\n",
              " '足立': 4,\n",
              " '長野': 1,\n",
              " '静岡': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff369724-73ba-408c-ad60-b096219a615d",
        "id": "7pu0PR0RoVB8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ',\n",
              " '三重',\n",
              " '京',\n",
              " '京都',\n",
              " '八戸',\n",
              " '八王子',\n",
              " '千葉',\n",
              " '名古屋',\n",
              " '和歌山',\n",
              " '和泉',\n",
              " '品川',\n",
              " '多摩',\n",
              " '大宮',\n",
              " '大阪',\n",
              " '奈良',\n",
              " '姫路',\n",
              " '宇都宮',\n",
              " '宮城',\n",
              " '富山',\n",
              " '山梨',\n",
              " '岡山',\n",
              " '川崎',\n",
              " '所沢',\n",
              " '春日部',\n",
              " '横浜',\n",
              " '水戸',\n",
              " '沖',\n",
              " '沼津',\n",
              " '滋賀',\n",
              " '熊谷',\n",
              " '相模',\n",
              " '神戸',\n",
              " '練馬',\n",
              " '群馬',\n",
              " '習志野',\n",
              " '足立',\n",
              " '長野',\n",
              " '静岡']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_real_classify_path = '/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/dataset/Pipeline_train_and_test/val_real_dataset_classify/'\n",
        "val_real_classify_folder = os.listdir(val_real_classify_path)\n",
        "len(val_real_classify_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dbeb1b-c54f-462e-f9a2-8ecfe44f2dc9",
        "id": "YYrXoW7zoVB8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val = []\n",
        "values_val = []\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  keys_val.append(folder)\n",
        "  values_val.append(len(os.listdir(path)))"
      ],
      "metadata": {
        "id": "aK7VWLWcoVB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip(keys_val, values_val))\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd16da9-1c1e-481a-c806-a37449117911",
        "id": "xOg7wOjpoVB8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1,\n",
              " '京都': 2,\n",
              " '八王子': 1,\n",
              " '名古屋': 1,\n",
              " '多摩': 1,\n",
              " '大阪': 1,\n",
              " '春日部': 1,\n",
              " '練馬': 2,\n",
              " '群馬': 1,\n",
              " '足立': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74556e1-7dcf-4af6-906c-97b5cfdaad06",
        "id": "9jfxNLjgoVB8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['なにわ', '京都', '八王子', '名古屋', '多摩', '大阪', '春日部', '練馬', '群馬', '足立']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/RecognitionCRNN/Recognition_CRNN_KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "gvbo1OH4oVB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  if folder in keys_val:\n",
        "    print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "    dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a0a3bf-420a-4735-b7ce-0e3a224f0685",
        "id": "tIbjNCfwoVB9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6dbb16-b783-4236-f9eb-db8964f95375",
        "id": "sh9BIodKoVB9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八王子': 0.3333333333333333,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '多摩': 0.0,\n",
              " '大阪': 0.0,\n",
              " '春日部': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '足立': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST 16032022 - TEST FULL TẬP TRAIN CHO CÁC CLASS Ở CP120\n",
        "dict_val_for_train = {}\n",
        "for folder in train_real_classify_folder:\n",
        "  path = train_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_TRAIN_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # if folder in keys_val:\n",
        "  print(\"CER_TRAIN_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  dict_val_for_train[str(folder)]=float(cer_rate)\n",
        "\n",
        "\n",
        "  # print(\"ACC_TRAIN_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5e0ff-2025-4c69-eb0a-6991c1f569fe",
        "id": "4nz53Rb5oVB9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_TRAIN_FOR_CLASS_なにわ:  0.0\n",
            "CER_TRAIN_FOR_CLASS_三重:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京:  0.0\n",
            "CER_TRAIN_FOR_CLASS_京都:  0.047619047619047616\n",
            "CER_TRAIN_FOR_CLASS_八戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_八王子:  0.3333333333333333\n",
            "CER_TRAIN_FOR_CLASS_千葉:  0.0\n",
            "CER_TRAIN_FOR_CLASS_名古屋:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_和歌山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_和泉:  0.25\n",
            "CER_TRAIN_FOR_CLASS_品川:  0.0\n",
            "CER_TRAIN_FOR_CLASS_多摩:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_大阪:  0.0\n",
            "CER_TRAIN_FOR_CLASS_奈良:  0.0\n",
            "CER_TRAIN_FOR_CLASS_姫路:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宇都宮:  0.0\n",
            "CER_TRAIN_FOR_CLASS_宮城:  0.0\n",
            "CER_TRAIN_FOR_CLASS_富山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_山梨:  0.0\n",
            "CER_TRAIN_FOR_CLASS_岡山:  0.0\n",
            "CER_TRAIN_FOR_CLASS_川崎:  0.0\n",
            "CER_TRAIN_FOR_CLASS_所沢:  0.5\n",
            "CER_TRAIN_FOR_CLASS_春日部:  0.0\n",
            "CER_TRAIN_FOR_CLASS_横浜:  0.0\n",
            "CER_TRAIN_FOR_CLASS_水戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沖:  0.0\n",
            "CER_TRAIN_FOR_CLASS_沼津:  0.0\n",
            "CER_TRAIN_FOR_CLASS_滋賀:  0.16666666666666666\n",
            "CER_TRAIN_FOR_CLASS_熊谷:  1.0\n",
            "CER_TRAIN_FOR_CLASS_相模:  0.0\n",
            "CER_TRAIN_FOR_CLASS_神戸:  0.0\n",
            "CER_TRAIN_FOR_CLASS_練馬:  0.0\n",
            "CER_TRAIN_FOR_CLASS_群馬:  0.125\n",
            "CER_TRAIN_FOR_CLASS_習志野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_足立:  0.0\n",
            "CER_TRAIN_FOR_CLASS_長野:  0.0\n",
            "CER_TRAIN_FOR_CLASS_静岡:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c48e83b-7e52-4580-b966-eb7e40fd389d",
        "id": "ugRcInNeoVB9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 0.0,\n",
              " '三重': 0.0,\n",
              " '京': 0.0,\n",
              " '京都': 0.047619047619047616,\n",
              " '八戸': 0.0,\n",
              " '八王子': 0.3333333333333333,\n",
              " '千葉': 0.0,\n",
              " '名古屋': 0.16666666666666666,\n",
              " '和歌山': 0.0,\n",
              " '和泉': 0.25,\n",
              " '品川': 0.0,\n",
              " '多摩': 0.0,\n",
              " '大宮': 0.0,\n",
              " '大阪': 0.0,\n",
              " '奈良': 0.0,\n",
              " '姫路': 0.0,\n",
              " '宇都宮': 0.0,\n",
              " '宮城': 0.0,\n",
              " '富山': 0.0,\n",
              " '山梨': 0.0,\n",
              " '岡山': 0.0,\n",
              " '川崎': 0.0,\n",
              " '所沢': 0.5,\n",
              " '春日部': 0.0,\n",
              " '横浜': 0.0,\n",
              " '水戸': 0.0,\n",
              " '沖': 0.0,\n",
              " '沼津': 0.0,\n",
              " '滋賀': 0.16666666666666666,\n",
              " '熊谷': 1.0,\n",
              " '相模': 0.0,\n",
              " '神戸': 0.0,\n",
              " '練馬': 0.0,\n",
              " '群馬': 0.125,\n",
              " '習志野': 0.0,\n",
              " '足立': 0.0,\n",
              " '長野': 0.0,\n",
              " '静岡': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lShu9UX4oVB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chạy kết quả trên từng class riêng biệt trên tập val, cụ thể là CP100**"
      ],
      "metadata": {
        "id": "oizLS-dZoVB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5\n",
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/drive/MyDrive/Recognition CRNN/Recognition part. CRNN KERAS/training_2/cp-0120.hdf5')"
      ],
      "metadata": {
        "id": "1M2H7zc0oVB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid = {}\n",
        "for folder in val_real_classify_folder:\n",
        "  path = val_real_classify_path + folder\n",
        "  path_image = os.listdir(path)\n",
        "  sum_cer = []\n",
        "  total = 0\n",
        "  acc = 0\n",
        "  letter_total = 0\n",
        "  letter_acc = 0\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS = []\n",
        "  for image in path_image:\n",
        "    path_img = path +'/'+image\n",
        "\n",
        "    img_pred = process_image(path_img)\n",
        "    net_out_value = model.predict(img_pred)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    newstr = pred_texts.replace(\"Z\", \"\")\n",
        "\n",
        "    # label = image_test_file[i][0: len(image_test_file[i])-4]\n",
        "\n",
        "    string = ''\n",
        "    for j in range(3):\n",
        "        if image[j]>='0' and image[j]<='9':\n",
        "          continue\n",
        "        else:\n",
        "          string += image[j]\n",
        "    if string.endswith('p'): string = string.rstrip(string[-1])\n",
        "    if string.endswith('.'): string = string.rstrip(string[-1])\n",
        "    # print('Predicted: '+newstr +\" \"+'Label: '+string)\n",
        "    cer = edit_distance(newstr, string)\n",
        "    error = cer/max(len(newstr), len(string))\n",
        "    \n",
        "\n",
        "    for i in range(min(len(newstr), len(string))):\n",
        "    #ti = test_img[i][:-9]\n",
        "        if newstr[i] == string[i]:\n",
        "            letter_acc += 1\n",
        "    letter_total += max(len(newstr), len(string))\n",
        "    if newstr == string:\n",
        "        acc += 1\n",
        "    total += 1\n",
        "    sum_cer.append(error)\n",
        "\n",
        "  cer_rate = sum(sum_cer) / len(path_image)\n",
        "  # CER_CHECKPOINT_VAL_FOR_CLASS.append(cer_rate)\n",
        "  dict_val_for_valid[str(folder)] = float(cer_rate)\n",
        "  print(\"CER_VAL_FOR_CLASS_{}: \".format(str(folder)),cer_rate)\n",
        "  # print(\"ACC_VAL_FOR_CLASS_{}: \".format(str(folder)), acc / total)\n",
        "  # print(\"letter ACC_FOR_CLASS_{}: \".format(str(folder)), letter_acc / letter_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc85d35-9cf1-45e4-e67e-a85373b45105",
        "id": "2-aLbxMBoVB9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CER_VAL_FOR_CLASS_名古屋:  1.0\n",
            "CER_VAL_FOR_CLASS_なにわ:  1.0\n",
            "CER_VAL_FOR_CLASS_京都:  0.25\n",
            "CER_VAL_FOR_CLASS_八王子:  1.0\n",
            "CER_VAL_FOR_CLASS_大阪:  0.5\n",
            "CER_VAL_FOR_CLASS_多摩:  1.0\n",
            "CER_VAL_FOR_CLASS_群馬:  1.0\n",
            "CER_VAL_FOR_CLASS_春日部:  0.3333333333333333\n",
            "CER_VAL_FOR_CLASS_練馬:  0.75\n",
            "CER_VAL_FOR_CLASS_足立:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_val_for_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7c94ac-1314-41d5-b95f-269cb6e21c6a",
        "id": "1GZNe3h4oVB-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'なにわ': 1.0,\n",
              " '京都': 0.25,\n",
              " '八王子': 1.0,\n",
              " '名古屋': 1.0,\n",
              " '多摩': 1.0,\n",
              " '大阪': 0.5,\n",
              " '春日部': 0.3333333333333333,\n",
              " '練馬': 0.75,\n",
              " '群馬': 1.0,\n",
              " '足立': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1up3JGwPoVB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}